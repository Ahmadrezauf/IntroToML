{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_project4_7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmadrezauf/IML_Projects/blob/master/task_4/main_project4_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRJ89EzIP3kM",
        "colab_type": "code",
        "outputId": "9d689758-311d-4d5a-8d46-80a68a461495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "import time\n",
        "\n",
        "import pdb\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras.backend as K\n",
        "from keras import Sequential\n",
        "\n",
        "from keras.layers import Dense, Dropout, Activation, SimpleRNN, LSTM, Conv1D, MaxPooling1D, AveragePooling1D, Embedding\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import AlphaDropout\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Lambda, Input, Layer\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import Callback,ModelCheckpoint, EarlyStopping\n",
        "from keras import initializers\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH0ZJQoregUG",
        "colab_type": "text"
      },
      "source": [
        "### Mounting drive and changing dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2uEzHW5QiXX",
        "colab_type": "code",
        "outputId": "ec922f9c-0bf9-4f33-8f51-8c3d0dacc377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount= True)\n",
        "import os\n",
        "workDir = '/content/drive/My Drive/ETHZ/IML/Project_4' #input('input the working directory: ')\n",
        "os.chdir(workDir)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BSkfTlDgJj_",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUIBN-TMgH5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# desired image size for input to layer in format (w,h)\n",
        "imgSize = (50,50)\n",
        "# embedding size\n",
        "emb_size = 10\n",
        "# margin for triplet loss\n",
        "alpha = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM677wGme1rb",
        "colab_type": "text"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdq2PXzleo_E",
        "colab_type": "text"
      },
      "source": [
        "## Importing image tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0DD8U4xkNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists('img_list.pickle'):\n",
        "  pickle_in = open( \"img_list.pickle\", \"rb\" )\n",
        "  food_images = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "  print(\"The image array was successfully loaded\")\n",
        "else:\n",
        "  num_food_images = 10000\n",
        "  path = 'food/'\n",
        "  imageSize = (450,300)\n",
        "\n",
        "  temp = np.zeros([imageSize[0],imageSize[1]])\n",
        "\n",
        "  food_images = [temp]*num_food_images\n",
        "\n",
        "  for indx in range(0, num_food_images):\n",
        "\n",
        "    # reading in images and adding it to array\n",
        "    fileName = f'{path}{indx:05d}.jpg'\n",
        "    # color correct from BGR to RGB \n",
        "    img = cv2.imread(fileName)\n",
        "    # resize image\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # resize image\n",
        "    img = cv2.resize(img, imageSize)\n",
        "    # appending image\n",
        "    food_images[indx] = img\n",
        "\n",
        "    if indx%100 == 0:\n",
        "      print(f'The progress is {round(indx/num_food_images*100,1)} %')\n",
        "\n",
        "  saveY = input('Do you want to save the generated array? y/n')\n",
        "  if saveY == 'y':\n",
        "    pickle_out = open(\"img_list.pickle\",\"wb\")\n",
        "    pickle.dump(food_images, pickle_out)\n",
        "    pickle_out.close()\n",
        "    print('The image array was successfully saved')\n",
        "  else:\n",
        "    print('The image array was NOT saved')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "624njwbDPa4R",
        "colab_type": "text"
      },
      "source": [
        "## Importing training and testing triplets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1xkIH06P2LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_train = pd.read_csv('train_triplets.txt', header = None, delim_whitespace=True)\n",
        "D_test = pd.read_csv('test_triplets.txt', header = None, delim_whitespace=True)\n",
        "\n",
        "train_triplets = np.array(D_train)\n",
        "test_triplets = np.array(D_test)\n",
        "\n",
        "num_train_triplets = np.shape(D_train)[0]\n",
        "num_test_triplets = np.shape(D_test)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEak_0VexfQh",
        "colab_type": "text"
      },
      "source": [
        "# k-fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG75AqSHJ_-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting data triplets\n",
        "k_fold = 5\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = k_fold, shuffle=True, random_state=1)\n",
        "\n",
        "X = np.array(D_train)\n",
        "# specify pseudo classification for split function\n",
        "y = np.ones(X.shape[0])\n",
        "\n",
        "k_index = list(kf.split(X,y))\n",
        "k_index = np.array(k_index)\n",
        "\n",
        "# visualize first k fold validation with training set\n",
        "X[k_index[0][0],:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtXazGDV5B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining data\n",
        "fold = X[k_index[0][0],:]\n",
        "validate = X[k_index[0][1],:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvUL9mR2fmCU",
        "colab_type": "text"
      },
      "source": [
        "## function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB1GvOda2JJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_batch(fold, batch_size=256, toSize = (450,300), flatten = True):\n",
        "    \n",
        "    if flatten:\n",
        "      x_anchors = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "      x_positives = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "      x_negatives = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "    else:\n",
        "      x_anchors = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "      x_positives = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "      x_negatives = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "          \n",
        "    # get random samples from train triplets\n",
        "    for i in range(0, batch_size):\n",
        "        # preprocessing\n",
        "\n",
        "        # We need to find an anchor, a positive example and a negative example\n",
        "        random_index = random.randint(0, fold.shape[0]-1)\n",
        "        triplet = fold[random_index]\n",
        "\n",
        "        # reshaping, normalizing and flattening images --> this will take more time than pre-processed data, but will eliminate RAM issues\n",
        "\n",
        "        x_anchor = cv2.resize(food_images[triplet[0]],toSize)/255.0\n",
        "        x_positive = cv2.resize(food_images[triplet[1]],toSize)/255.0\n",
        "        x_negative = cv2.resize(food_images[triplet[2]],toSize)/255.0\n",
        "\n",
        "        if flatten:\n",
        "          x_anchor = np.reshape(x_anchor, np.prod(x_anchor.shape))\n",
        "          x_positive = np.reshape(x_positive, np.prod(x_positive.shape))\n",
        "          x_negative = np.reshape(x_negative, np.prod(x_negative.shape))\n",
        "             \n",
        "        x_anchors[i] = x_anchor\n",
        "        x_positives[i] = x_positive\n",
        "        x_negatives[i] = x_negative\n",
        "        \n",
        "    return [x_anchors, x_positives, x_negatives]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X13C_RzyHpZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example how to use function\n",
        "\n",
        "tr = create_batch(fold, batch_size=3, toSize = (25,25), flatten = False)\n",
        "\n",
        "for n in range(0,len(tr[0])):\n",
        "  for i in range(0,3):\n",
        "    plt.subplot(len(tr[0]),3, 3*n + i+1)\n",
        "    plt.imshow(tr[i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSeNaBdfQNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(fold, batch_size=256, toSize = (10,10), flatten=True):\n",
        "    while True:\n",
        "        x = create_batch(fold, batch_size, toSize, flatten)\n",
        "        y = np.zeros((batch_size, 3*emb_size))\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa_rxV2yjX7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_through(fold, toSize = (450,300), flatten = True):\n",
        "    \n",
        "    batch_size = len(fold)\n",
        "\n",
        "    if flatten:\n",
        "      x_anchors = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "      x_positives = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "      x_negatives = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "    else:\n",
        "      x_anchors = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "      x_positives = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "      x_negatives = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "\n",
        "    \n",
        "    # get random samples from train triplets\n",
        "    for i in range(0, len(fold)):\n",
        "        # preprocessing\n",
        "\n",
        "        # We need to find an anchor, a positive example and a negative example\n",
        "        triplet = fold[i]\n",
        "\n",
        "        # reshaping, normalizing and flattening images --> this will take more time than pre-processed data, but will eliminate RAM issues\n",
        "\n",
        "        x_anchor = cv2.resize(food_images[triplet[0]],toSize)/255.0\n",
        "        x_positive = cv2.resize(food_images[triplet[1]],toSize)/255.0\n",
        "        x_negative = cv2.resize(food_images[triplet[2]],toSize)/255.0\n",
        "\n",
        "        if flatten:\n",
        "          x_anchor = np.reshape(x_anchor, np.prod(x_anchor.shape))\n",
        "          x_positive = np.reshape(x_positive, np.prod(x_positive.shape))\n",
        "          x_negative = np.reshape(x_negative, np.prod(x_negative.shape))\n",
        "             \n",
        "        x_anchors[i] = x_anchor\n",
        "        x_positives[i] = x_positive\n",
        "        x_negatives[i] = x_negative\n",
        "\n",
        "        # yield [x_anchors, x_positives, x_negatives]\n",
        "        \n",
        "    return [x_anchors, x_positives, x_negatives]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PxZtXalrG5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_triplets(examples, imgSize):\n",
        "    plt.figure(figsize=(6, 2))\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, 1 + i)\n",
        "        plt.imshow(np.reshape(examples[i], (imgSize[1], imgSize[0], 3)))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "examples = create_batch(fold,1)\n",
        "plot_triplets(examples,(450,300))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtwro22MfFgm",
        "colab_type": "text"
      },
      "source": [
        "# Defining Model & network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSEy0L8kqrz2",
        "colab_type": "text"
      },
      "source": [
        "## Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2HpgSKhp4BD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# embedding_model = tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.Dense(emb_size, activation='relu', input_shape=(imgSize[0]*imgSize[1]*3,)),\n",
        "#     tf.keras.layers.Dense(emb_size, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# embedding_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqeu1JRRRJP_",
        "colab_type": "text"
      },
      "source": [
        "## Embedding layer with convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hENpRgcRHmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_model = keras.Sequential()\n",
        "embedding_model.add(keras.Input(shape=(imgSize[1], imgSize[0], 3))) \n",
        "\n",
        "embedding_model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
        "embedding_model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "embedding_model.add(layers.Conv2D(32, 3, strides=2, activation=\"relu\"))\n",
        "embedding_model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "# embedding_model.add(layers.GlobalMaxPooling2D())\n",
        "\n",
        "embedding_model.add(layers.Flatten())\n",
        "\n",
        "embedding_model.add(layers.Dense(emb_size, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCnVAkxVVoqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVWeMpV7rnqz",
        "colab_type": "text"
      },
      "source": [
        "## Siamese network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCpwKX-xp4xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_anchor = tf.keras.layers.Input(shape=(imgSize[1],imgSize[0],3))\n",
        "input_positive = tf.keras.layers.Input(shape=(imgSize[1],imgSize[0],3))\n",
        "input_negative = tf.keras.layers.Input(shape=(imgSize[1],imgSize[0],3))\n",
        "\n",
        "embedding_anchor = embedding_model(input_anchor)\n",
        "embedding_positive = embedding_model(input_positive)\n",
        "embedding_negative = embedding_model(input_negative)\n",
        "\n",
        "output = tf.keras.layers.concatenate([embedding_anchor, embedding_positive, embedding_negative], axis=1)\n",
        "\n",
        "net = tf.keras.models.Model([input_anchor, input_positive, input_negative], output)\n",
        "net.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emsDMH-7t3ee",
        "colab_type": "text"
      },
      "source": [
        "## Triplet loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlhVb37vtw7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_true, y_pred):\n",
        "    anchor, positive, negative = y_pred[:,:emb_size], y_pred[:,emb_size:2*emb_size], y_pred[:,2*emb_size:]\n",
        "    positive_dist = tf.reduce_mean(tf.square(anchor - positive), axis=1)\n",
        "    negative_dist = tf.reduce_mean(tf.square(anchor - negative), axis=1)\n",
        "    triplet_loss = tf.maximum(positive_dist - negative_dist + alpha, 0.)\n",
        "    loss = tf.reduce_mean(triplet_loss)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WryQNM_d7GB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(net, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT4Sz8PMfwMq",
        "colab_type": "text"
      },
      "source": [
        "# Training & saving network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWq2FsVntxJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from pca_plotter import PCAPlotter\n",
        "import math\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "steps_per_epoch = math.floor(fold.shape[0]/batch_size)\n",
        "\n",
        "net.compile(loss=triplet_loss, optimizer='adamax')\n",
        "\n",
        "result =  net.fit(\n",
        "    data_generator(fold, batch_size, imgSize,flatten=False),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVQS8YdNctqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving as pickle object\n",
        "# pickle_out = open(\"net.pickle\",\"wb\")\n",
        "# pickle.dump(result, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "import keras.losses\n",
        "keras.losses.custom_loss = triplet_loss\n",
        "\n",
        "from keras.models import load_model\n",
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "description = input('optional file description: ')\n",
        "\n",
        "filepath = f'{workDir}/models/{round(now.timestamp())}_sb_model_{description}.h5'\n",
        "print(filepath)\n",
        "net.save(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNjC4FSL1Qhh",
        "colab_type": "text"
      },
      "source": [
        "# Test predictions & save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR_w0HMQpgfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optionally loading a model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "inp = input('Select model to run: ')\n",
        "\n",
        "net_saved = load_model(inp, custom_objects={'triplet_loss': triplet_loss})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "323Lss7TRtl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for transforming predicted embeddings to required prediction 0 or 1\n",
        "# anchor: dish A, positive: dish B, negative: dish C\n",
        "# if distance A to B < A to C then A is more similar to B than to C -> return 1\n",
        "\n",
        "def similar_dish(prediction):\n",
        "  out = [0]*len(prediction)\n",
        "  for idx, vec in enumerate(prediction):\n",
        "    anchor, positive, negative = vec[:emb_size], vec[emb_size:2*emb_size], vec[2*emb_size:]\n",
        "    positive_dist = np.mean(np.square(anchor - positive))\n",
        "    negative_dist = np.mean(np.square(anchor - negative))\n",
        "\n",
        "    if positive_dist < negative_dist:\n",
        "      out[idx] = 1\n",
        "    else:\n",
        "      out[idx] = 0\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pchw_EmWylW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# less memory intense way of creating predictions\n",
        "def predict_vec(fold, batch_size = 1000, toSize = (450,300), flatten = True):\n",
        "\n",
        "  if flatten:\n",
        "    x_anchors = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "    x_positives = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "    x_negatives = np.zeros((batch_size, toSize[0]*toSize[1]*3))\n",
        "  else:\n",
        "    x_anchors = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "    x_positives = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "    x_negatives = np.zeros([batch_size, toSize[1], toSize[0], 3])\n",
        "\n",
        "  predictions = []\n",
        "  c = 0\n",
        "  totlen=0\n",
        "  # get random samples from train triplets\n",
        "  for i in range(0, len(fold)):\n",
        "\n",
        "      if i%500 == 0:\n",
        "        print(f'The progress is {round(i/len(fold)*100,1)} %')\n",
        "      # preprocessing\n",
        "\n",
        "      # We need to find an anchor, a positive example and a negative example\n",
        "      triplet = fold[i]\n",
        "\n",
        "      # reshaping, normalizing and flattening images --> this will take more time than pre-processed data, but will eliminate RAM issues\n",
        "\n",
        "      x_anchor = cv2.resize(food_images[triplet[0]],toSize)/255.0\n",
        "      x_positive = cv2.resize(food_images[triplet[1]],toSize)/255.0\n",
        "      x_negative = cv2.resize(food_images[triplet[2]],toSize)/255.0\n",
        "\n",
        "      if flatten:\n",
        "        x_anchor = np.reshape(x_anchor, np.prod(x_anchor.shape))\n",
        "        x_positive = np.reshape(x_positive, np.prod(x_positive.shape))\n",
        "        x_negative = np.reshape(x_negative, np.prod(x_negative.shape))\n",
        "\n",
        "      x_anchors[c] = x_anchor\n",
        "      x_positives[c] = x_positive\n",
        "      x_negatives[c] = x_negative\n",
        "\n",
        "      if c >= (batch_size-1) or i == (len(fold)-1):\n",
        "        if i == (len(fold)-1):\n",
        "          print(f'End with c {c}')\n",
        "        print(f'i is {i}, Predicting...')\n",
        "        # print(x_anchors[-1])        \n",
        "        X = [x_anchors[0:c], x_positives[0:c], x_negatives[0:c]]\n",
        "        print(np.array(X).shape)\n",
        "        vec = net.predict(X)\n",
        "        predictions.append(similar_dish(vec))\n",
        "\n",
        "        # predictions.append(similar_dish(vec))\n",
        "        print('End of predictions...')\n",
        "\n",
        "        totlen = totlen + len(vec)\n",
        "\n",
        "        # resetting c\n",
        "        c = -1\n",
        "\n",
        "        # break\n",
        "\n",
        "      c = c + 1\n",
        "\n",
        "  pred_flat = []\n",
        "  for li in predictions:\n",
        "    for elem in li:\n",
        "      pred_flat.append(elem)\n",
        "  \n",
        "  print(f' The length of the vector is: {totlen}')\n",
        "\n",
        "  return pred_flat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsPeYiGjCXNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_val = predict_vec(validate, batch_size = 501, toSize = imgSize, flatten=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_in7LY52kwBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There is still a discrepancy\n",
        "print(len(outVec))\n",
        "print(len(validate))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccnfqRVU4Ql_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# percentage accuracy\n",
        "perc_accuracy = round(np.sum(pr_val)/len(pr_val)*100,1)\n",
        "print(f'The accurate predictions from the validation set is {perc_accuracy} %')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ig5ArIZREG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deprecated\n",
        "\n",
        "# X = run_through(validate, toSize = imgSize, flatten=False)\n",
        "\n",
        "# predicted_embeddings = net.predict(X)\n",
        "# predicted_embeddings.shape\n",
        "\n",
        "# making predictions for the test set in the first fold\n",
        "# sv_f1 = [similar_dish(emb) for emb in predicted_embeddings]\n",
        "# perc_accurate = round(np.sum(sv_f1)/len(sv_f1)*100,1)\n",
        "# print(f'The percentage of accurate predictions for the first fold test set is: {perc_accurate} %')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ7Hfm4gfQpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_test = predict_vec(D_test, batch_size = 1000, toSize = imgSize, flatten=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZjvKRkN5egS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# percentage accuracy\n",
        "positive_given = round(np.sum(pr_test)/len(pr_test)*100,1)\n",
        "print(f'Predicted positive images given is {positive_given} %')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-0dCVnOqqBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deprecated\n",
        "D_test = np.array(D_test)\n",
        "X = run_through(D_test, toSize = imgSize, flatten=False)\n",
        "\n",
        "predicted_embeddings = net.predict(X)\n",
        "predicted_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coj-wjTsq1T1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # making predictions for the test set in the first fold\n",
        "sv_pr = similar_dish(predicted_embeddings)\n",
        "perc_accurate = round(np.sum(sv_pr)/len(sv_pr)*100,1)\n",
        "print(f'The percentage of accurate predictions for the test set is: {perc_accurate} %')\n",
        "print(np.array(sv_pr).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1nihzZiZqwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "description = input('Add an optional description to the result file: ')\n",
        "filepath = f'{workDir}/results/{round(now.timestamp())}_sb_result_{description}.txt'\n",
        "np.savetxt(filepath, sv_pr, fmt='%i', )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DnFZqiR6y1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}