{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"./data/train.csv\", header = 0)\n",
    "y = dat['y']\n",
    "X = dat.iloc[:,2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm2 = np.cos(X)\n",
    "fm3 = np.multiply(X, X)\n",
    "fm4 = np.exp(X)\n",
    "fm5 = pd.DataFrame(np.ones(X.shape[0]))\n",
    "\n",
    "frames = [X, fm3, fm4, fm2, fm5]\n",
    "dat = pd.concat(frames, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      700 non-null    float64\n",
      " 1   x2      700 non-null    float64\n",
      " 2   x3      700 non-null    float64\n",
      " 3   x4      700 non-null    float64\n",
      " 4   x5      700 non-null    float64\n",
      " 5   x1      700 non-null    float64\n",
      " 6   x2      700 non-null    float64\n",
      " 7   x3      700 non-null    float64\n",
      " 8   x4      700 non-null    float64\n",
      " 9   x5      700 non-null    float64\n",
      " 10  x1      700 non-null    float64\n",
      " 11  x2      700 non-null    float64\n",
      " 12  x3      700 non-null    float64\n",
      " 13  x4      700 non-null    float64\n",
      " 14  x5      700 non-null    float64\n",
      " 15  x1      700 non-null    float64\n",
      " 16  x2      700 non-null    float64\n",
      " 17  x3      700 non-null    float64\n",
      " 18  x4      700 non-null    float64\n",
      " 19  x5      700 non-null    float64\n",
      " 20  0       700 non-null    float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 115.0 KB\n"
     ]
    }
   ],
   "source": [
    "# look at dataframe\n",
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale all the features\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "dat_scaled = min_max_scaler.fit_transform(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11474567 -0.06678273  0.14563605  0.29974673  0.10464111 -0.14308345\n",
      " -0.15877945 -0.07922056 -0.23689053  0.01577394  0.09395678 -0.08811665\n",
      "  0.14189713  0.2698375   0.12425499  0.18535497  0.20101083  0.12142954\n",
      "  0.28011013  0.02590653  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# ridge regression with cross-validation\n",
    "regularization_param = np.linspace(0.01, 100, 1000)\n",
    "\n",
    "ridge_model = RidgeCV(alphas= regularization_param, fit_intercept= False, normalize= True, cv = 10).fit(dat_scaled, y)\n",
    "score = ridge_model.score(dat, y)\n",
    "coefs = ridge_model.coef_\n",
    "\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save coefficients\n",
    "np.savetxt(\"results.csv\", coefs, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try repeated cross-validation ridge regression for improvement\n",
    "* The idea is that the way the data set is split into folds is random. Repeating the cross-validation multiple times improves the accuracy of the model\n",
    "* Observation: the coefficients appear to be identical -> no change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of the alpha values for each repetition (10 repetition)\n",
    "alpha = np.zeros(10)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    # ridge regression with cross-validation\n",
    "    regularization_param = np.linspace(0.01, 100, 1000)\n",
    "\n",
    "    ridge_model = RidgeCV(alphas= regularization_param, fit_intercept= False, normalize= True, cv = 10).fit(dat_scaled, y)\n",
    "    score = ridge_model.score(dat, y)\n",
    "    coefs = ridge_model.coef_\n",
    "\n",
    "    alpha[i] = ridge_model.alpha_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # use the mean of all alpha values\n",
    "alpha_opt = np.mean(alpha)\n",
    "\n",
    "# train model with this alpha value\n",
    "ridge_regression = Ridge(alpha = alpha_opt,tol=1e-9, normalize= False, fit_intercept = False, max_iter=1000000).fit(dat_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = ridge_regression.coef_\n",
    "print(coefs)\n",
    "\n",
    "# save coefficients\n",
    "np.savetxt(\"repeatedkfold_results.csv\", coefs, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try splitting into training and test data before scaling\n",
    "* The thought is that if we scale the training and test data together then there is potentially some type of information from the test data contained in the scaled training data and the reported performance is then too optimistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1000)\n"
     ]
    }
   ],
   "source": [
    "# ridge regression with cross-validation\n",
    "regularization_param = np.linspace(0.01, 100, 1000)\n",
    "\n",
    "# mse of each fold and regularization parameter\n",
    "mse = np.zeros((10, len(regularization_param)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into folds\n",
    "kf = KFold(n_splits = 10)    # maybe also try shuffeling the data points (shuffel = True)\n",
    "fold_indx = 0\n",
    "\n",
    "# loop over the sets\n",
    "for train_indx, test_indx in kf.split(dat):\n",
    "    dat_train = dat.iloc[train_indx,:]\n",
    "    dat_test = dat.iloc[test_indx, :]\n",
    "    y_train = dat.iloc[train_indx, :]\n",
    "    y_test = dat.iloc[test_indx, :]\n",
    "\n",
    "    # scale all the features\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    dat_train_scaled = min_max_scaler.fit_transform(dat_train)\n",
    "    dat_test_scaled = min_max_scaler.transform(dat_test)\n",
    "    \n",
    "    for i in range(0, len(regularization_param)):\n",
    "        # fit ridge model for all ridge regression parameters\n",
    "        ridge_model = Ridge(alpha = regularization_param[i],tol=1e-9, normalize= False, fit_intercept = False, max_iter=1000000).fit(dat_train_scaled, y_train)\n",
    "        # compute prediction for test data and determine the MSE\n",
    "        pred = ridge_model.predict(dat_test)\n",
    "        MSE = mean_squared_error(y_test, pred)\n",
    "        mse[fold_indx, i] = MSE\n",
    "        \n",
    "    fold_indx = fold_indx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# which regularization parameter yields the smallest mse for each training/test split yields the smallest mse\n",
    "\n",
    "alpha_minimal_mse = np.argmin(mse, axis = 1)\n",
    "print(alpha_minimal_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
