{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "\n",
    "# load data from csv file\n",
    "df_train_features = pd.read_csv ('train_features.csv')\n",
    "df_train_labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "# Load test data\n",
    "df_test_features = pd.read_csv ('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Histogram of the output labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels.hist()\n",
    "\n",
    "# with PdfPages(\"./Results/Labels_histogram.pdf\") as export_pdf:\n",
    "#     for i in list(df_train_labels)[1:]:\n",
    "#         df_train_labels.hist(column = i, bins = 100)\n",
    "#         export_pdf.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see the class imbalance problem here. Other observations:\n",
    "  * Heartrate, RRate, ABPm,  distribution is similar to a normal distribution\n",
    "  * SpO2 is like a censored normal distribution. \n",
    "  * For all of the other features, class imbalance is an obvious problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic strategy that could be used here: Upsample both classes! Do the upsampling efficiently, not just replicating the datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data inspection: \n",
    "#############################################\n",
    "# range of the provided data?\n",
    "print(df_train_features.agg([min, max]))\n",
    "\n",
    "# Boxplotting the data\n",
    "# fig2, ax2 = plt.subplots()\n",
    "# ax2.set_title('BUN')\n",
    "# ax2.boxplot(df_train_features.iloc[:,5], notch=True)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.boxplot(data = df_train_features.iloc[:,1:])\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "\n",
    "# with PdfPages(\"./Results/Train_columns_boxplot.pdf\") as export_pdf:\n",
    "#     for i in list(df_train_labels)[1:]:\n",
    "#         df_train_labels.hist(column = i, bins = 100)\n",
    "#         export_pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix\n",
    "corr = df_train_features.corr()\n",
    "\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns, \n",
    "        vmin=-1, vmax=1, center=0, \n",
    "           cmap=sns.diverging_palette(20, 220, n=200))\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing pattern of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much missing data? \n",
    "print(\"Percentage of missing values:\")\n",
    "print(df_train_features.isnull().sum(axis=0) / len(df_train_features))\n",
    "\n",
    "msno.matrix(df_train_features)\n",
    "\n",
    "# Plotting the correlation between the missing values\n",
    "msno.heatmap(df_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient by patient pre-processing for imputation and feature generation\n",
    "\n",
    "# get variables from train features\n",
    "variables = df_train_features.columns[2:]\n",
    "\n",
    "# get all pids, to impute and pre-process individually\n",
    "train_pids = df_train_features['pid'].unique()\n",
    "\n",
    "for pid in train_pids:\n",
    "    # dataframe for this pid\n",
    "    df = df_train_features.loc[df_train_features['pid'] == pid]\n",
    "    \n",
    "    for var in variables:\n",
    "        # how many NaN are in there for this variable\n",
    "        data = df[var]\n",
    "        num_nan = data.isnull().sum(axis=0)\n",
    "        if num_nan == 12:\n",
    "            continue\n",
    "        \n",
    "        data = data.to_numpy()\n",
    "           \n",
    "        imp = SimpleImputer(missing_values = np.nan)\n",
    "        train_imputed = imp.fit_transform(data.reshape(-1, 1))\n",
    "    \n",
    "        df_train_features.loc[df_train_features['pid'] == pid,var] = train_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the time series\n",
    "data_array = np.empty([len(train_pids), len(variables)])\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for pid in train_pids:\n",
    "    \n",
    "    df = df_train_features.loc[df_train_features['pid'] == pid]\n",
    "    j = 0\n",
    "    \n",
    "    for var in variables:\n",
    "        # how many NaN are in there for this variable\n",
    "        data = df[var]\n",
    "        num_nan = data.isnull().sum(axis=0)\n",
    "        if num_nan == 12:\n",
    "            data_array[i, j] = np.nan\n",
    "            j = j + 1\n",
    "            continue\n",
    "        data = data.to_numpy()\n",
    "        data_array[i, j] = np.mean(data)\n",
    "        j = j + 1 \n",
    "        \n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "#imp = SimpleImputer(strategy=\"mean\")\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_train_agg_imputed_features = imputer.fit_transform(data_array)\n",
    "#print(df_train_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "# standard_scalar = preprocessing.StandardScaler()\n",
    "\n",
    "data_train_scaled = min_max_scaler.fit_transform(df_train_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REARRANGE THE LABELS, TO MATCH THE REARRANGED FEATURES\n",
    "df_train_labels_sorted = df_train_labels.sort_values(by = 'pid')\n",
    "# print(df_train_labels_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the training data after imputing and aggregating\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.boxplot(data = pd.DataFrame(data_train_scaled))\n",
    "ax.set_xticklabels(\n",
    "    list(df_train_features),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the correlation between the \n",
    "pd.DataFrame(data_train_scaled).corrwith(other = pd.DataFrame(df_train_agg_imputed_features), method = \"spearman\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(data_train_scaled)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, df_train_labels[['LABEL_BaseExcess']]], axis = 1)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA for LABEL_BaseExcess', fontsize = 20)\n",
    "targets = [0, 1]\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['LABEL_BaseExcess'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data inspection: \n",
    "#############################################\n",
    "# range of the provided data?\n",
    "print(df_test_features.agg([min, max]))\n",
    "\n",
    "# how much missing data? \n",
    "print(\"number of missing values:\")\n",
    "print(df_test_features.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate data for each pid\n",
    "# df_test_aggregate_features = df_test_features.groupby('pid').agg('median')\n",
    "\n",
    "# #print(df_test_aggregate_features)\n",
    "\n",
    "# # collect all test pids\n",
    "test_pids = list(set(df_test_features.pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient by patient pre-processing for imputation and feature generation\n",
    "\n",
    "# get variables from train features\n",
    "variables_test = df_test_features.columns[2:]\n",
    "\n",
    "# get all pids, to impute and pre-process individually\n",
    "test_pids = list(set(df_test_features.pid))\n",
    "\n",
    "for pid in test_pids:\n",
    "    # dataframe for this pid\n",
    "    df = df_test_features.loc[df_test_features['pid'] == pid]\n",
    "    \n",
    "    for var in variables_test:\n",
    "        # how many NaN are in there for this variable\n",
    "        data = df[var]\n",
    "        num_nan = data.isnull().sum(axis=0)\n",
    "        if num_nan == 12:\n",
    "            continue\n",
    "        \n",
    "        data = data.to_numpy()\n",
    "           \n",
    "        imp = SimpleImputer(missing_values = np.nan)\n",
    "        test_imputed = imp.fit_transform(data.reshape(-1, 1))\n",
    "    \n",
    "        df_test_features.loc[df_test_features['pid'] == pid,var] = test_imputed\n",
    "\n",
    "# aggregate the time series\n",
    "data_array = np.empty([len(test_pids), len(variables_test)])\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for pid in test_pids:\n",
    "    \n",
    "    df = df_test_features.loc[df_test_features['pid'] == pid]\n",
    "    j = 0\n",
    "    \n",
    "    for var in variables:\n",
    "        # how many NaN are in there for this variable\n",
    "        data = df[var]\n",
    "        num_nan = data.isnull().sum(axis=0)\n",
    "        if num_nan == 12:\n",
    "            data_array[i, j] = np.nan\n",
    "            j = j + 1\n",
    "            continue\n",
    "        data = data.to_numpy()\n",
    "        data_array[i, j] = np.mean(data)\n",
    "        j = j + 1 \n",
    "        \n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove time from data frame \n",
    "# df_test_agg_features = df_test_aggregate_features.drop(['Time'], axis = 1)\n",
    "print(df_test_agg_features)\n",
    "print(data_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "# should we impute it with the same imputer that we've used for train?\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_test_agg_imputed_features = imputer.fit_transform(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale test data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "data_test_scaled = min_max_scaler.fit_transform(df_test_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with support vector machine classification and use probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "for i in range(1, 12):\n",
    "    clf = SVC(kernel = 'poly', degree = 5, class_weight = 'balanced', verbose = True)\n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    # pred = clf.predict(df_test_agg_imputed_features)\n",
    "    # columns_1.append(pred)\n",
    "     \n",
    "    # compute probabilites as opposed to predictions\n",
    "    dual_coefficients = clf.dual_coef_    # do we have to normalize with norm of this vector ?\n",
    "    distance_hyperplane = clf.decision_function(data_test_scaled)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplane[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "    columns_1.append(probability)\n",
    "\n",
    "\n",
    "    \n",
    "    distance_hyperplace_train = clf.decision_function(data_train_scaled)\n",
    "    probability = np.empty(len(distance_hyperplace_train))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplace_train[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplace_train[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplace_train[j]))\n",
    "      \n",
    "    tmp = roc_auc_score(y_score= probability, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels that have a real value\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "    clf_w = SVR(kernel = 'poly', degree =5)\n",
    "    parameters = {'C':np.linspace(1,10, 5)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 4,\n",
    "                                       refit = True, scoring = 'r2', verbose = 1, n_jobs=6)\n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    pred_train = clf.predict(data_train_scaled)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    \n",
    "    pred = clf.predict(data_test_scaled)\n",
    "    columns_2.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with Support vector regression and then compute sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "for i in range(1,12):\n",
    "    \n",
    "    clf = SVR(kernel = 'poly', degree = 3, max_iter = 10000)\n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    pred = clf.predict(data_test_scaled)\n",
    "    prob = np.empty(len(pred))\n",
    "    for j in range(0, len(pred)):\n",
    "        prob[j] = 1 / (1 + math.exp(-pred[j]))\n",
    "    columns_1.append(prob)\n",
    "    \n",
    "    pred_train = clf.predict(data_train_scaled)\n",
    "    prob_train = np.empty(len(pred_train))\n",
    "    for j in range(0, len(pred_train)):\n",
    "        prob_train[j] = 1 / (1 + math.exp(-pred_train[j]))    \n",
    "    tmp = roc_auc_score(y_score= prob_train, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# labels that have a real value\n",
    "\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "    clf_w = LinearSVR()\n",
    "    parameters = {'C':np.linspace(0.1,10, 20)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 5,\n",
    "                                       refit = True, scoring = 'r2', verbose = 1, n_jobs=6)\n",
    "    \n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(clf.cv_results_)\n",
    "    pred = clf.predict(data_test_scaled)\n",
    "    columns_2.append(pred)\n",
    "    \n",
    "    pred_train = clf.predict(data_train_scaled)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(columns_final))\n",
    "result = pd.DataFrame(columns_final).transpose()\n",
    "result.columns = list(df_train_labels)\n",
    "result.to_csv('./Results/prediction.csv.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./Results/prediction.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
