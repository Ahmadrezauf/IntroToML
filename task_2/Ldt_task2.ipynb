{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, mutual_info_classif, mutual_info_regression\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "\n",
    "# load data from csv file\n",
    "df_train_features = pd.read_csv ('train_features.csv')\n",
    "df_train_labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "# Load test data\n",
    "df_test_features = pd.read_csv ('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Histogram of the output labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x129110b50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x10c871490>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x10c8aab10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x10c8ec1d0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x10c920850>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x10c955ed0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x12913a610>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x12916ebd0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x12916ec10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1291b13d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x129212b10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x12925f690>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x129294d10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1292d53d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x12930ba50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x12934b110>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_labels.hist()\n",
    "\n",
    "# with PdfPages(\"./Results/Labels_histogram.pdf\") as export_pdf:\n",
    "#     for i in list(df_train_labels)[1:]:\n",
    "#         df_train_labels.hist(column = i, bins = 100)\n",
    "#         export_pdf.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see the class imbalance problem here. Other observations:\n",
    "  * Heartrate, RRate, ABPm,  distribution is similar to a normal distribution\n",
    "  * SpO2 is like a censored normal distribution. \n",
    "  * For all of the other features, class imbalance is an obvious problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic strategy that could be used here: Upsample both classes! Do the upsampling efficiently, not just replicating the datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data inspection: \n",
    "#############################################\n",
    "# range of the provided data?\n",
    "print(df_train_features.agg([min, max]))\n",
    "\n",
    "# Boxplotting the data\n",
    "# fig2, ax2 = plt.subplots()\n",
    "# ax2.set_title('BUN')\n",
    "# ax2.boxplot(df_train_features.iloc[:,5], notch=True)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.boxplot(data = df_train_features.iloc[:,1:])\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "\n",
    "# with PdfPages(\"./Results/Train_columns_boxplot.pdf\") as export_pdf:\n",
    "#     for i in list(df_train_labels)[1:]:\n",
    "#         df_train_labels.hist(column = i, bins = 100)\n",
    "#         export_pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix\n",
    "corr = df_train_features.corr()\n",
    "\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns, \n",
    "        vmin=-1, vmax=1, center=0, \n",
    "           cmap=sns.diverging_palette(20, 220, n=200))\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing pattern of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much missing data? \n",
    "print(\"Percentage of missing values:\")\n",
    "print(df_train_features.isnull().sum(axis=0) / len(df_train_features))\n",
    "\n",
    "msno.matrix(df_train_features)\n",
    "\n",
    "# Plotting the correlation between the missing values\n",
    "msno.heatmap(df_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "#imp = SimpleImputer(strategy=\"mean\")\n",
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "df_train_agg_imputed_features = imputer.fit_transform(df_train_agg_features)\n",
    "#print(df_train_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "# standard_scalar = preprocessing.StandardScaler()\n",
    "\n",
    "data_train_scaled = min_max_scaler.fit_transform(df_train_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REARRANGE THE LABELS, TO MATCH THE REARRANGED FEATURES\n",
    "# df_train_labels_sorted = df_train_labels.sort_values(by = 'pid')\n",
    "# print(df_train_labels_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the training data after imputing and aggregating\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.boxplot(data = pd.DataFrame(data_train_scaled))\n",
    "ax.set_xticklabels(\n",
    "    list(df_train_features),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the correlation between the \n",
    "pd.DataFrame(data_train_scaled).corrwith(other = pd.DataFrame(df_train_agg_imputed_features), method = \"spearman\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(data_train_scaled)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, df_train_labels[['LABEL_BaseExcess']]], axis = 1)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA for LABEL_BaseExcess', fontsize = 20)\n",
    "targets = [0, 1]\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['LABEL_BaseExcess'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data inspection: \n",
    "#############################################\n",
    "# range of the provided data?\n",
    "print(df_test_features.agg([min, max]))\n",
    "\n",
    "# how much missing data? \n",
    "print(\"number of missing values:\")\n",
    "print(df_test_features.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate data for each pid\n",
    "# df_test_aggregate_features = df_test_features.groupby('pid').agg('median')\n",
    "\n",
    "#print(df_test_aggregate_features)\n",
    "\n",
    "# # collect all test pids\n",
    "test_pids = list(set(df_test_features.pid))\n",
    "df_test_agg_features = df_test_features.groupby('pid').agg([np.min, np.max, np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "# should we impute it with the same imputer that we've used for train?\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "df_test_agg_imputed_features = imputer.fit_transform(df_test_agg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale test data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "data_test_scaled = min_max_scaler.fit_transform(df_test_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_train_scaled).to_csv(\"./Results/dat_train_scaled.csv\")\n",
    "pd.DataFrame(data_test_scaled).to_csv(\"./Results/dat_test_scaled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with support vector machine classification and use probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18995, 20)\n",
      "[False False False False False  True False False False False False False\n",
      " False  True  True False False False  True False  True False False False\n",
      "  True False  True False False False False False False False False  True\n",
      " False False False False  True False False  True False False False False\n",
      " False  True False False False  True  True False  True False False False\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False  True False False False False False False False  True False\n",
      " False  True False False False False False False False False False False]\n",
      "(12664, 20)\n",
      "[False False False False False  True False False False False False False\n",
      " False  True  True False False False  True False  True False False False\n",
      "  True False  True False False False False False False False False  True\n",
      " False False False False  True False False  True False False False False\n",
      " False  True False False False  True  True False  True False False False\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False  True False False False False False False False  True False\n",
      " False  True False False False False False False False False False False]\n",
      "[LibSVM]ROC AUC for feature LABEL_BaseExcess  :  0.8287871500191502\n",
      "(18995, 20)\n",
      "[False False False  True False False False False  True False False False\n",
      " False False False False False False False  True False False  True False\n",
      " False False  True False False  True False False  True False False False\n",
      " False False False False False False False False  True  True False False\n",
      " False False False False False False False  True False False  True False\n",
      " False False False  True False False False False False False False  True\n",
      " False False False False  True  True False False  True  True False False\n",
      " False False False False False False False False False  True  True False\n",
      " False False False False  True False False False False False False False]\n",
      "(12664, 20)\n",
      "[False False False  True False False False False  True False False False\n",
      " False False False False False False False  True False False  True False\n",
      " False False  True False False  True False False  True False False False\n",
      " False False False False False False False False  True  True False False\n",
      " False False False False False False False  True False False  True False\n",
      " False False False  True False False False False False False False  True\n",
      " False False False False  True  True False False  True  True False False\n",
      " False False False False False False False False False  True  True False\n",
      " False False False False  True False False False False False False False]\n",
      "[LibSVM]ROC AUC for feature LABEL_Fibrinogen  :  0.9766837575609952\n",
      "(18995, 20)\n",
      "[False False False False False False False False False False False False\n",
      " False False False  True False  True False False False False False False\n",
      " False  True False False False False False  True False False  True False\n",
      " False False False False False False False False False False False  True\n",
      "  True False False False False  True  True  True False False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False  True False False False False False False  True\n",
      " False False False False False False False False False  True  True False\n",
      " False  True False False  True  True False False False False False  True]\n",
      "(12664, 20)\n",
      "[False False False False False False False False False False False False\n",
      " False False False  True False  True False False False False False False\n",
      " False  True False False False False False  True False False  True False\n",
      " False False False False False False False False False False False  True\n",
      "  True False False False False  True  True  True False False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False  True False False False False False False  True\n",
      " False False False False False False False False False  True  True False\n",
      " False  True False False  True  True False False False False False  True]\n",
      "[LibSVM]ROC AUC for feature LABEL_AST  :  0.8569899474660376\n",
      "(18995, 20)\n",
      "[False False False False False  True False  True False False False False\n",
      " False False False False False  True  True False False False False  True\n",
      " False False False False False False False False False False False  True\n",
      " False False False False  True  True  True False False False False  True\n",
      "  True False False False  True False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False  True False False False False False  True False False False False\n",
      " False False  True False  True  True  True False False False False False]\n",
      "(12664, 20)\n",
      "[False False False False False  True False  True False False False False\n",
      " False False False False False  True  True False False False False  True\n",
      " False False False False False False False False False False False  True\n",
      " False False False False  True  True  True False False False False  True\n",
      "  True False False False  True False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False  True False False False False False  True False False False False\n",
      " False False  True False  True  True  True False False False False False]\n",
      "[LibSVM]ROC AUC for feature LABEL_Alkalinephos  :  0.8604815928428228\n",
      "(18995, 20)\n",
      "[False False False False False  True False False False False False  True\n",
      " False False False False False  True  True False False False False  True\n",
      " False  True False False False False False False  True False False False\n",
      " False  True False  True False False False False False False False  True\n",
      " False False False  True  True  True False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      "  True False False False  True  True  True False False False False  True]\n",
      "(12664, 20)\n",
      "[False False False False False  True False False False False False  True\n",
      " False False False False False  True  True False False False False  True\n",
      " False  True False False False False False False  True False False False\n",
      " False  True False  True False False False False False False False  True\n",
      " False False False  True  True  True False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      "  True False False False  True  True  True False False False False  True]\n",
      "[LibSVM]ROC AUC for feature LABEL_Bilirubin_total  :  0.8845110869243693\n",
      "(18995, 20)\n",
      "[False  True False False False False  True False  True False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False  True False  True False  True False False False\n",
      " False  True  True  True False False  True False False False  True False\n",
      "  True False False False False False False False False False False False\n",
      "  True False False False False False False  True False  True False False\n",
      " False False False False False  True False  True False False False  True]\n",
      "(12664, 20)\n",
      "[False  True False False False False  True False  True False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False  True False  True False  True False False False\n",
      " False  True  True  True False False  True False False False  True False\n",
      "  True False False False False False False False False False False False\n",
      "  True False False False False False False  True False  True False False\n",
      " False False False False False  True False  True False False False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]ROC AUC for feature LABEL_Lactate  :  0.8989060284299264\n",
      "(18995, 20)\n",
      "[False False False False False False False  True False False False False\n",
      " False False False  True False False  True False  True  True False False\n",
      " False False False False  True False False  True False False False False\n",
      "  True False  True False False  True False False False False  True False\n",
      " False False False  True False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False  True False False False False  True False False  True False\n",
      " False False False False  True False  True False  True False False False]\n",
      "(12664, 20)\n",
      "[False False False False False False False  True False False False False\n",
      " False False False  True False False  True False  True  True False False\n",
      " False False False False  True False False  True False False False False\n",
      "  True False  True False False  True False False False False  True False\n",
      " False False False  True False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False  True False False False False  True False False  True False\n",
      " False False False False  True False  True False  True False False False]\n",
      "[LibSVM]ROC AUC for feature LABEL_TroponinI  :  0.9562972118070021\n",
      "(18995, 20)\n",
      "[False False  True False  True False False  True False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False  True False False False False False False False False False  True\n",
      " False False False  True False False False False False False False False\n",
      " False False False  True False  True False False False  True False False\n",
      " False False False False False False False False False  True  True False\n",
      " False False False False False  True False  True  True False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False  True False False  True False  True]\n",
      "(12664, 20)\n",
      "[False False  True False  True False False  True False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False  True False False False False False False False False False  True\n",
      " False False False  True False False False False False False False False\n",
      " False False False  True False  True False False False  True False False\n",
      " False False False False False False False False False  True  True False\n",
      " False False False False False  True False  True  True False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False  True False False  True False  True]\n",
      "[LibSVM]ROC AUC for feature LABEL_SaO2  :  0.8959293766355956\n",
      "(18995, 20)\n",
      "[False False  True False False False  True False False False  True False\n",
      " False False False False  True  True False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False  True False False False False False  True False False False False\n",
      " False False False False False  True  True  True False False False False\n",
      " False  True False  True False False False False  True False  True False\n",
      " False False False False False False False False False False False False\n",
      " False  True  True False False False False False False False False False\n",
      " False  True False  True False False False False False False  True False]\n",
      "(12664, 20)\n",
      "[False False  True False False False  True False False False  True False\n",
      " False False False False  True  True False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False  True False False False False False  True False False False False\n",
      " False False False False False  True  True  True False False False False\n",
      " False  True False  True False False False False  True False  True False\n",
      " False False False False False False False False False False False False\n",
      " False  True  True False False False False False False False False False\n",
      " False  True False  True False False False False False False  True False]\n",
      "[LibSVM]ROC AUC for feature LABEL_Bilirubin_direct  :  0.9482165576638572\n",
      "(18995, 20)\n",
      "[False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False  True\n",
      " False False False False False  True False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      "  True False False False False False  True  True  True False False  True\n",
      " False False False False False False False False  True False  True False\n",
      " False False False False False False  True False False  True False  True\n",
      " False False False False False  True False False False False False False\n",
      " False  True False  True False False  True False  True False False  True]\n",
      "(12664, 20)\n",
      "[False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False  True\n",
      " False False False False False  True False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      "  True False False False False False  True  True  True False False  True\n",
      " False False False False False False False False  True False  True False\n",
      " False False False False False False  True False False  True False  True\n",
      " False False False False False  True False False False False False False\n",
      " False  True False  True False False  True False  True False False  True]\n",
      "[LibSVM]ROC AUC for feature LABEL_EtCO2  :  0.9350736231511956\n",
      "(18995, 20)\n",
      "[False False False False  True False False False False False False False\n",
      " False False False  True False False False False  True False False False\n",
      " False False False False False  True False False False False False False\n",
      " False  True False False False False False False False False  True False\n",
      " False False False  True False  True False False  True False  True  True\n",
      " False False False False False  True False  True  True False False False\n",
      "  True False False False False False  True False False False False False\n",
      " False False  True False False  True False False False False False False\n",
      " False False False False False  True False False  True False False False]\n",
      "(12664, 20)\n",
      "[False False False False  True False False False False False False False\n",
      " False False False  True False False False False  True False False False\n",
      " False False False False False  True False False False False False False\n",
      " False  True False False False False False False False False  True False\n",
      " False False False  True False  True False False  True False  True  True\n",
      " False False False False False  True False  True  True False False False\n",
      "  True False False False False False  True False False False False False\n",
      " False False  True False False  True False False False False False False\n",
      " False False False False False  True False False  True False False False]\n",
      "[LibSVM]ROC AUC for feature LABEL_Sepsis  :  0.9575467427295932\n"
     ]
    }
   ],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "for i in range(1, 12):\n",
    "   \n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_classif, mode ='k_best', param=20)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "\n",
    "    \n",
    "    #clf = BaggingClassifier(SVC(kernel = 'poly', degree = 5, class_weight = 'balanced', verbose = True, C = 10))\n",
    "    clf = SVC(kernel = 'poly', degree = 5, class_weight = 'balanced', verbose = True, C = 10)\n",
    "    \n",
    "    #parameters = {'C':np.linspace(0.1,10,20)}\n",
    "#     clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 4,\n",
    "#                                        refit = True, scoring = 'roc_auc', verbose = 1, n_jobs=6)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "    #print(clf.best_params_)\n",
    "    # compute probabilites as opposed to predictions\n",
    "    #dual_coefficients = clf.dual_coef_    # do we have to normalize with norm of this vector ?\n",
    "    \n",
    "    distance_hyperplane = clf.decision_function(test_features)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplane[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "    columns_1.append(probability)\n",
    "\n",
    "    \n",
    "    distance_hyperplace_train = clf.decision_function(train_features)\n",
    "    probability = np.empty(len(distance_hyperplace_train))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplace_train[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplace_train[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplace_train[j]))\n",
    "    \n",
    "    tmp = roc_auc_score(y_score= probability, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# labels that have a real value\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param=20)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    clf_w = SVR(kernel = 'poly', degree = 3)\n",
    "    parameters = {'C':np.linspace(1,10, 3)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 4,\n",
    "                                       refit = True, scoring = 'r2', verbose = 1, n_jobs=6)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    print(clf.cv_results_)\n",
    "    \n",
    "    pred_train = clf.predict(train_features)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    \n",
    "    pred = clf.predict(test_features)\n",
    "    columns_2.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with Support vector regression and then compute sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "\n",
    "# columns_1 = [test_pids]\n",
    "\n",
    "# for i in range(1,12):\n",
    "    \n",
    "#     clf = SVR(kernel = 'poly', degree = 3, max_iter = 10000)\n",
    "#     clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "#     pred = clf.predict(data_test_scaled)\n",
    "#     prob = np.empty(len(pred))\n",
    "#     for j in range(0, len(pred)):\n",
    "#         prob[j] = 1 / (1 + math.exp(-pred[j]))\n",
    "#     columns_1.append(prob)\n",
    "    \n",
    "#     pred_train = clf.predict(data_train_scaled)\n",
    "#     prob_train = np.empty(len(pred_train))\n",
    "#     for j in range(0, len(pred_train)):\n",
    "#         prob_train[j] = 1 / (1 + math.exp(-pred_train[j]))    \n",
    "#     tmp = roc_auc_score(y_score= prob_train, y_true= df_train_labels.iloc[:,i])\n",
    "#     print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 out of  40 | elapsed:   15.0s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.20297593, 1.52776003, 1.86675704, 2.09101903, 2.238864  ,\n",
      "       2.38156706, 2.4960168 , 2.59432793, 2.59636354, 2.3342033 ]), 'std_fit_time': array([0.02427534, 0.15090169, 0.13693127, 0.08988519, 0.08353116,\n",
      "       0.08588908, 0.06840303, 0.02372801, 0.04784499, 0.2095477 ]), 'mean_score_time': array([0.00151891, 0.00151867, 0.00118172, 0.00116915, 0.00127709,\n",
      "       0.00125945, 0.00179344, 0.00111431, 0.00106311, 0.00072503]), 'std_score_time': array([2.70914821e-04, 1.72374520e-04, 2.12430987e-04, 1.66565145e-04,\n",
      "       1.15651751e-04, 2.37657405e-05, 1.06731646e-03, 1.69495604e-04,\n",
      "       2.40797749e-04, 8.86729628e-05]), 'param_C': masked_array(data=[0.1, 1.2000000000000002, 2.3000000000000003,\n",
      "                   3.4000000000000004, 4.5, 5.6, 6.7, 7.800000000000001,\n",
      "                   8.9, 10.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.1}, {'C': 1.2000000000000002}, {'C': 2.3000000000000003}, {'C': 3.4000000000000004}, {'C': 4.5}, {'C': 5.6}, {'C': 6.7}, {'C': 7.800000000000001}, {'C': 8.9}, {'C': 10.0}], 'split0_test_score': array([-0.01154324, -0.00816643, -0.00878432, -0.00874171, -0.00993969,\n",
      "       -0.01071009, -0.01154014, -0.01384164, -0.00760348, -0.01228367]), 'split1_test_score': array([-0.0135656 , -0.01081396, -0.00976502, -0.01085321, -0.01172488,\n",
      "       -0.01137093, -0.01166418, -0.01112793, -0.01285174, -0.01280457]), 'split2_test_score': array([-0.02222212, -0.0185737 , -0.01925369, -0.01759932, -0.01878428,\n",
      "       -0.02178358, -0.02294687, -0.02013542, -0.01844155, -0.01936901]), 'split3_test_score': array([-0.01390441, -0.01113244, -0.01120133, -0.01182445, -0.0097737 ,\n",
      "       -0.01386647, -0.01233962, -0.0146274 , -0.01148111, -0.01150908]), 'mean_test_score': array([-0.01530884, -0.01217163, -0.01225109, -0.01225467, -0.01255564,\n",
      "       -0.01443277, -0.0146227 , -0.0149331 , -0.01259447, -0.01399158]), 'std_test_score': array([0.0040922 , 0.00387141, 0.00413332, 0.00328083, 0.00367656,\n",
      "       0.00440421, 0.00481558, 0.00327216, 0.003886  , 0.00313869]), 'rank_test_score': array([10,  1,  2,  3,  4,  7,  8,  9,  5,  6], dtype=int32)}\n",
      "R2 for feature LABEL_RRate  :  -0.010031587401247322\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 out of  40 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.0810743 , 0.55939025, 0.90581071, 1.26440197, 1.38999587,\n",
      "       1.58947021, 1.71329075, 1.86397088, 1.91576874, 1.68888575]), 'std_fit_time': array([0.01022928, 0.08454557, 0.06334751, 0.03603409, 0.08993327,\n",
      "       0.03716532, 0.06191481, 0.10618143, 0.07305454, 0.26868279]), 'mean_score_time': array([0.00173855, 0.00124699, 0.00107449, 0.00131726, 0.00108016,\n",
      "       0.0012697 , 0.0011487 , 0.00129622, 0.00088072, 0.00077379]), 'std_score_time': array([5.42325575e-04, 1.29422136e-04, 1.57318903e-04, 4.24803437e-05,\n",
      "       2.27617239e-04, 4.50050987e-05, 1.41967003e-04, 2.12492849e-04,\n",
      "       5.46901768e-05, 4.49472773e-05]), 'param_C': masked_array(data=[0.1, 1.2000000000000002, 2.3000000000000003,\n",
      "                   3.4000000000000004, 4.5, 5.6, 6.7, 7.800000000000001,\n",
      "                   8.9, 10.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.1}, {'C': 1.2000000000000002}, {'C': 2.3000000000000003}, {'C': 3.4000000000000004}, {'C': 4.5}, {'C': 5.6}, {'C': 6.7}, {'C': 7.800000000000001}, {'C': 8.9}, {'C': 10.0}], 'split0_test_score': array([-0.03513815, -0.01484011, -0.01383073, -0.01449844, -0.01431   ,\n",
      "       -0.01489344, -0.01383122, -0.014042  , -0.01509106, -0.01625987]), 'split1_test_score': array([-0.03262476, -0.01351464, -0.01353121, -0.01306899, -0.01247763,\n",
      "       -0.01294919, -0.01220394, -0.01214922, -0.01264162, -0.0130827 ]), 'split2_test_score': array([-0.04657523, -0.0223371 , -0.02171659, -0.02157371, -0.02151267,\n",
      "       -0.02129553, -0.02059315, -0.02025264, -0.02116107, -0.02094078]), 'split3_test_score': array([-0.02788078, -0.10269375, -0.33103033, -0.63924889, -1.01908314,\n",
      "       -1.28543357, -1.41765097, -1.56680789, -1.54215917, -1.94659423]), 'mean_test_score': array([-0.03555473, -0.0383464 , -0.09502722, -0.17209751, -0.26684586,\n",
      "       -0.33364293, -0.36606982, -0.40331294, -0.39776323, -0.4992194 ]), 'std_test_score': array([0.00687567, 0.03730295, 0.13629599, 0.2697292 , 0.43431753,\n",
      "       0.54952526, 0.60713881, 0.67175081, 0.66072458, 0.83564692]), 'rank_test_score': array([ 1,  2,  3,  4,  5,  6,  7,  9,  8, 10], dtype=int32)}\n",
      "R2 for feature LABEL_ABPm  :  -0.027817062756235078\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 out of  40 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.21988142, 1.78769386, 2.25111133, 2.47263706, 2.42570055,\n",
      "       2.55534494, 2.69144481, 2.7555567 , 2.7431587 , 2.50967115]), 'std_fit_time': array([0.00977382, 0.150775  , 0.15302315, 0.06194534, 0.04391186,\n",
      "       0.0430222 , 0.02706935, 0.01688295, 0.07166798, 0.09934296]), 'mean_score_time': array([0.001266  , 0.00118244, 0.00139087, 0.00119162, 0.00125253,\n",
      "       0.00119698, 0.00113696, 0.00100124, 0.0011043 , 0.00073409]), 'std_score_time': array([3.67922434e-05, 1.50484483e-04, 1.11696162e-04, 1.84314293e-04,\n",
      "       8.37752983e-05, 3.07760894e-05, 1.09950958e-04, 2.11448551e-04,\n",
      "       1.95269137e-04, 1.07449569e-04]), 'param_C': masked_array(data=[0.1, 1.2000000000000002, 2.3000000000000003,\n",
      "                   3.4000000000000004, 4.5, 5.6, 6.7, 7.800000000000001,\n",
      "                   8.9, 10.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.1}, {'C': 1.2000000000000002}, {'C': 2.3000000000000003}, {'C': 3.4000000000000004}, {'C': 4.5}, {'C': 5.6}, {'C': 6.7}, {'C': 7.800000000000001}, {'C': 8.9}, {'C': 10.0}], 'split0_test_score': array([-0.00324825, -0.00949013, -0.01146489, -0.00839573, -0.01350378,\n",
      "       -0.01369832, -0.01001857, -0.01882026, -0.01730828, -0.01973058]), 'split1_test_score': array([-0.00396235, -0.00806827, -0.00914487, -0.01289944, -0.01115958,\n",
      "       -0.01012515, -0.00777896, -0.01717634, -0.01387804, -0.01359401]), 'split2_test_score': array([-0.00155013, -0.0098116 , -0.00955396, -0.01016832, -0.01097579,\n",
      "       -0.01299785, -0.012888  , -0.01474466, -0.0094543 , -0.0179933 ]), 'split3_test_score': array([-0.00309529, -0.01091421, -0.01417153, -0.01352943, -0.01535437,\n",
      "       -0.02092222, -0.01453859, -0.01830615, -0.02714781, -0.01484924]), 'mean_test_score': array([-0.00296401, -0.00957105, -0.01108381, -0.01124823, -0.01274838,\n",
      "       -0.01443589, -0.01130603, -0.01726185, -0.01694711, -0.01654178]), 'std_test_score': array([0.00087945, 0.00101573, 0.00198615, 0.00207565, 0.00180473,\n",
      "       0.00397703, 0.00260047, 0.00157025, 0.00651433, 0.00244077]), 'rank_test_score': array([ 1,  2,  3,  4,  6,  7,  5, 10,  9,  8], dtype=int32)}\n",
      "R2 for feature LABEL_SpO2  :  -0.0015437430242064565\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 out of  40 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.03495628, 0.29119098, 0.49984592, 0.66408604, 0.84731632,\n",
      "       1.03355968, 1.23394626, 1.3570857 , 1.43295556, 1.28313106]), 'std_fit_time': array([0.00487962, 0.03606594, 0.04123057, 0.02614105, 0.08332978,\n",
      "       0.10051447, 0.06323536, 0.09389402, 0.10589017, 0.25503908]), 'mean_score_time': array([0.00096709, 0.00107807, 0.00112605, 0.00113785, 0.00104368,\n",
      "       0.00113034, 0.00099289, 0.00115252, 0.00103575, 0.00082916]), 'std_score_time': array([0.00011935, 0.00016115, 0.00020795, 0.00023863, 0.00015671,\n",
      "       0.00012926, 0.00016617, 0.00018927, 0.00018031, 0.00023669]), 'param_C': masked_array(data=[0.1, 1.2000000000000002, 2.3000000000000003,\n",
      "                   3.4000000000000004, 4.5, 5.6, 6.7, 7.800000000000001,\n",
      "                   8.9, 10.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.1}, {'C': 1.2000000000000002}, {'C': 2.3000000000000003}, {'C': 3.4000000000000004}, {'C': 4.5}, {'C': 5.6}, {'C': 6.7}, {'C': 7.800000000000001}, {'C': 8.9}, {'C': 10.0}], 'split0_test_score': array([-0.02162494, -0.00757188, -0.00705323, -0.00696991, -0.00671764,\n",
      "       -0.00681405, -0.006474  , -0.00680913, -0.00745209, -0.00618634]), 'split1_test_score': array([-0.01539622, -0.00573388, -0.00576021, -0.00550356, -0.00560714,\n",
      "       -0.00507214, -0.00531185, -0.00526555, -0.00542397, -0.00603708]), 'split2_test_score': array([-0.01483939, -0.00399273, -0.00382395, -0.00375448, -0.00342124,\n",
      "       -0.00373586, -0.00422315, -0.00364373, -0.0039844 , -0.00392174]), 'split3_test_score': array([-0.01560843, -0.00715924, -0.00638562, -0.00653132, -0.00677884,\n",
      "       -0.00601453, -0.00639211, -0.0057796 , -0.00670141, -0.00607689]), 'mean_test_score': array([-0.01686724, -0.00611443, -0.00575575, -0.00568982, -0.00563122,\n",
      "       -0.00540914, -0.00560028, -0.0053745 , -0.00589047, -0.00555551]), 'std_test_score': array([0.00276117, 0.00140198, 0.00120541, 0.00123764, 0.00135848,\n",
      "       0.00114605, 0.00091789, 0.00114343, 0.00131786, 0.00094484]), 'rank_test_score': array([10,  9,  7,  6,  5,  2,  4,  1,  8,  3], dtype=int32)}\n",
      "R2 for feature LABEL_Heartrate  :  -0.0017322926444713893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#labels that have a real value\n",
    "\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "    \n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param=20)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "\n",
    "\n",
    "    clf_w = LinearSVR()\n",
    "    parameters = {'C':np.linspace(0.1,10, 10)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 4,\n",
    "                                       refit = True, scoring = 'r2', verbose = 1, n_jobs=6)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "    print(clf.cv_results_)\n",
    "    pred = clf.predict(test_features)\n",
    "    columns_2.append(pred)\n",
    "    \n",
    "    pred_train = clf.predict(train_features)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest Classifier\n",
    "columns_1 = [test_pids]\n",
    "for i in range(1, 12):\n",
    "    clf = RandomForestClassifier(min_samples_leaf=2, class_weight='balanced', oob_score=False, bootstrap=False)\n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(clf.oob_score)\n",
    "    # compute probabilites as opposed to predictions\n",
    "    probability = clf.apply(data_test_scaled)\n",
    "    probs = [i[1] for i in probability] \n",
    "    columns_1.append(probs)\n",
    "    \n",
    "    \n",
    "    probability = clf.predict_proba(data_train_scaled)\n",
    "\n",
    "    probs = [i[1] for i in probability]            \n",
    "    tmp = roc_auc_score(y_score= probs, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(columns_final))\n",
    "result = pd.DataFrame(columns_final).transpose()\n",
    "result.columns = list(df_train_labels)\n",
    "result.to_csv('./Results/prediction.csv.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./Results/prediction.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
