{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, mutual_info_classif, mutual_info_regression, f_regression, f_classif\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "\n",
    "# load data from csv file\n",
    "df_train_features = pd.read_csv ('train_features.csv')\n",
    "df_train_labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "# Load test data\n",
    "df_test_features = pd.read_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels = df_train_labels.sort_values('pid')\n",
    "df_train_features = df_train_features.sort_values(['pid', 'Time'])\n",
    "\n",
    "# Droping time\n",
    "df_train_features = df_train_features.drop('Time', axis = 1)\n",
    "df_test_features = df_test_features.drop('Time', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Histogram of the output labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels.hist()\n",
    "\n",
    "# with PdfPages(\"./Results/Labels_histogram.pdf\") as export_pdf:\n",
    "#     for i in list(df_train_labels)[1:]:\n",
    "#         df_train_labels.hist(column = i, bins = 100)\n",
    "#         export_pdf.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see the class imbalance problem here. Other observations:\n",
    "  * Heartrate, RRate, ABPm,  distribution is similar to a normal distribution\n",
    "  * SpO2 is like a censored normal distribution. \n",
    "  * For all of the other features, class imbalance is an obvious problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic strategy that could be used here: Upsample both classes! Do the upsampling efficiently, not just replicating the datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot over features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data inspection: \n",
    "#############################################\n",
    "# range of the provided data?\n",
    "print(df_train_features.agg([min, max]))\n",
    "\n",
    "# Boxplotting the data\n",
    "# fig2, ax2 = plt.subplots()\n",
    "# ax2.set_title('BUN')\n",
    "# ax2.boxplot(df_train_features.iloc[:,5], notch=True)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.boxplot(data = df_train_features.iloc[:,1:])\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "\n",
    "# with PdfPages(\"./Results/Train_columns_boxplot.pdf\") as export_pdf:\n",
    "#     for i in list(df_train_labels)[1:]:\n",
    "#         df_train_labels.hist(column = i, bins = 100)\n",
    "#         export_pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix\n",
    "corr = df_train_features.corr()\n",
    "\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns, \n",
    "        vmin=-1, vmax=1, center=0, \n",
    "           cmap=sns.diverging_palette(20, 220, n=200))\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing pattern of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much missing data? \n",
    "print(\"Percentage of missing values:\")\n",
    "print(df_train_features.isnull().sum(axis=0) / len(df_train_features))\n",
    "\n",
    "msno.matrix(df_train_features)\n",
    "\n",
    "# Plotting the correlation between the missing values\n",
    "msno.heatmap(df_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have less than a percent NA\n",
    "NA_percent = 0.7\n",
    "NA_percent_severe = 0.91\n",
    "\n",
    "sel_features = df_train_features.isnull().sum(axis=0) < (NA_percent * df_train_features.shape[0])\n",
    "inds = np.where(sel_features == True)\n",
    "\n",
    "sel_features_2 = (df_train_features.isnull().sum(axis=0) < (NA_percent_severe * df_train_features.shape[0])) & (df_train_features.isnull().sum(axis=0) > (NA_percent * df_train_features.shape[0]))        \n",
    "inds_2 = np.where(sel_features_2 == True)\n",
    "\n",
    "sel_features_3 = df_train_features.isnull().sum(axis=0) > (NA_percent_severe * df_train_features.shape[0])\n",
    "inds_3 = np.where(sel_features_3 == True)\n",
    "\n",
    "vars_class1 = df_train_features.columns[inds[0]]\n",
    "vars_class2 = df_train_features.columns[inds_2[0]]\n",
    "vars_class3 = df_train_features.columns[inds_3[0]]\n",
    "vars_classes = [vars_class1, vars_class2, vars_class3]\n",
    "\n",
    "print(\"--------Our Columns are are: \",df_train_features.columns.drop(\"pid\"))\n",
    "print(\"--------Labels are: \", df_train_labels.columns)\n",
    "print(\"********Var classes are: \" ,vars_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_technique(dat, variables, pids, vars_classes):\n",
    "    \n",
    "    vars_class1 = vars_classes[0]\n",
    "    vars_class2 = vars_classes[1]\n",
    "    vars_class3 = vars_classes[2]\n",
    "    \n",
    "    aggregated_dataframe = []\n",
    "    for pid in pids:\n",
    "        # dataframe for this pid\n",
    "        df = dat.loc[dat['pid'] == pid]\n",
    "        calculated_features = []\n",
    "        for var in variables:\n",
    "            # how many NaN are in there for this variable\n",
    "            data = df[var].tolist()\n",
    "#             num_nan = np.count_nonzero(np.isnan(data))\n",
    "            if var == \"Age\":\n",
    "                calculated_features.append(data[0])\n",
    "                \n",
    "            elif var in vars_class1:\n",
    "                calculated_features = calculated_features + data\n",
    "#                 calculated_features.append(np.nanmean(data))\n",
    "#                 calculated_features.append(np.nanstd(data))\n",
    "                \n",
    "            elif var in vars_class2:\n",
    "                calculated_features.append(np.nanmean(data))\n",
    "                calculated_features.append(np.nanstd(data))\n",
    "                calculated_features.append(np.nanmin(data))\n",
    "                calculated_features.append(np.nanmax(data))\n",
    "            else:\n",
    "                calculated_features.append(np.nanmean(data))\n",
    "                calculated_features.append(np.nanstd(data))\n",
    "                \n",
    "        aggregated_dataframe.append(calculated_features)\n",
    "        \n",
    "    aggregated_dataframe = pd.DataFrame(aggregated_dataframe)\n",
    "    return(aggregated_dataframe)\n",
    " \n",
    "train_pids = df_train_features['pid'].unique()\n",
    "df_train_agg_features = aggregation_technique(df_train_features, df_train_features.columns.drop(\"pid\"), train_pids, vars_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train_agg_features.shape)\n",
    "print(df_train_agg_features.columns)\n",
    "print(df_train_agg_features)\n",
    "pd.DataFrame(data_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_pids[1:50])\n",
    "# print(df_train_labels['pid'].tolist()[1:50])\n",
    "print(np.nanmean(df_train_features['Age'].tolist()))\n",
    "print(np.nanvar(df_train_features['Age'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the imputer with a simple Random Forest estimator\n",
    "# imp = IterativeImputer(RandomForestRegressor(n_estimators=5), max_iter=10, random_state=1)\n",
    "\n",
    "# #perform filling\n",
    "# df_train_agg_imputed_features = pd.DataFrame(imp.fit_transform(df_train_agg_features), columns=df_train_agg_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "#imp = SimpleImputer(strategy=\"mean\")\n",
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "\n",
    "df_train_agg_imputed_features = imputer.fit_transform(df_train_agg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "# standard_scalar = preprocessing.StandardScaler()\n",
    "\n",
    "data_train_scaled = min_max_scaler.fit_transform(df_train_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the training data after imputing and aggregating\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.boxplot(data = pd.DataFrame(data_train_scaled))\n",
    "ax.set_xticklabels(\n",
    "    list(df_train_features),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the correlation between the \n",
    "pd.DataFrame(data_train_scaled).corrwith(other = pd.DataFrame(df_train_agg_imputed_features), method = \"spearman\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(data_train_scaled)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, df_train_labels[[df_train_labels.columns[1]]]], axis = 1)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA for label i', fontsize = 20)\n",
    "targets = [0, 1]\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf[df_train_labels.columns[1]] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pids = df_test_features['pid'].unique()\n",
    "df_test_agg_features = aggregation_technique(df_test_features, df_test_features.columns.drop(\"pid\"),\n",
    "                                             test_pids, vars_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test_agg_features.isna().sum(axis = 0).tolist()[0:100])\n",
    "print(df_train_agg_features.isna().sum(axis = 0).tolist()[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "# should we impute it with the same imputer that we've used for train?\n",
    "\n",
    "imputer = KNNImputer(n_neighbors= 10)\n",
    "df_test_agg_imputed_features = imputer.fit_transform(df_test_agg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test_agg_imputed_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5fb9e026868d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# scale test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmin_max_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRobustScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_agg_imputed_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test_agg_imputed_features' is not defined"
     ]
    }
   ],
   "source": [
    "# scale test data\n",
    "min_max_scaler = preprocessing.RobustScaler()\n",
    "data_test_scaled = min_max_scaler.fit_transform(df_test_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_train_scaled).to_csv(\"./Results/dat_train_scaled.csv\", index = False)\n",
    "pd.DataFrame(data_test_scaled).to_csv(\"./Results/dat_test_scaled.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If want to run from here:\n",
    "data_train_scaled = pd.read_csv(\"./Results/dat_train_scaled.csv\")\n",
    "data_test_scaled = pd.read_csv(\"./Results/dat_test_scaled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with support vector machine classification and use probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 7, 9, 11, 12, 15, 16, 17, 19, 21, 22, 25, 28, 32, 36, 40, 42, 44, 46, 52, 58, 59, 60, 65, 66, 67, 68, 72]\n",
      "[10001 10003 10004 10005 10008 10011 10017 10018 10019 10025 10028  1003\n",
      " 10032 10033 10039  1004 10041 10042 10043 10046 10047  1005 10051  1006\n",
      " 10060 10062 10063 10064 10067]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(df_test_features.pid))[1:30])\n",
    "test_pids = df_test_features['pid'].unique()\n",
    "print(test_pids[1:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature  LABEL_BaseExcess\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  3.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 1}\n",
      "0.8289746900517461\n",
      "ROC AUC for feature LABEL_BaseExcess  :  0.8903110074327428\n",
      "For feature  LABEL_Fibrinogen\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 0.1}\n",
      "0.7467884545122396\n",
      "ROC AUC for feature LABEL_Fibrinogen  :  0.799909795802379\n",
      "For feature  LABEL_AST\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "/usr/local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  4.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 1}\n",
      "0.6737523179374584\n",
      "ROC AUC for feature LABEL_AST  :  0.8141784159719205\n",
      "For feature  LABEL_Alkalinephos\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "/usr/local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  4.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 1}\n",
      "0.6776695736255007\n",
      "ROC AUC for feature LABEL_Alkalinephos  :  0.8149017204927829\n",
      "For feature  LABEL_Bilirubin_total\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  4.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 1}\n",
      "0.6770352953668907\n",
      "ROC AUC for feature LABEL_Bilirubin_total  :  0.8107431102548835\n",
      "For feature  LABEL_Lactate\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "/usr/local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  3.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 1}\n",
      "0.7435848317556011\n",
      "ROC AUC for feature LABEL_Lactate  :  0.8599516858243754\n",
      "For feature  LABEL_TroponinI\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  2.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 0.1}\n",
      "0.7194664321313397\n",
      "ROC AUC for feature LABEL_TroponinI  :  0.7698806647224924\n",
      "For feature  LABEL_SaO2\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "/usr/local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  4.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 1}\n",
      "0.7610907629728793\n",
      "ROC AUC for feature LABEL_SaO2  :  0.8657966117727522\n",
      "For feature  LABEL_Bilirubin_direct\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 0.1}\n",
      "0.710027274580626\n",
      "ROC AUC for feature LABEL_Bilirubin_direct  :  0.8381013812437997\n",
      "For feature  LABEL_EtCO2\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 0.1}\n",
      "0.8064457612490123\n",
      "ROC AUC for feature LABEL_EtCO2  :  0.8640885550882911\n",
      "For feature  LABEL_Sepsis\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]{'C': 0.1}\n",
      "0.6542154499915278\n",
      "ROC AUC for feature LABEL_Sepsis  :  0.7592515886820468\n"
     ]
    }
   ],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "\n",
    "for i in range(1, 12):\n",
    "    \n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= f_classif, mode ='k_best', param=50)\n",
    "    train_features = pd.DataFrame(transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i]))\n",
    "    print(\"For feature \", df_train_labels.columns[i])\n",
    "#     print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "    test_features = pd.DataFrame(transformer.transform(data_test_scaled))\n",
    "\n",
    "#     values_1 = train_features.loc[df_train_labels[df_train_labels.columns[i]] == 1]\n",
    "#     values_0 = train_features.loc[df_train_labels[df_train_labels.columns[i]] == 0]\n",
    "#     values_0 = resample(values_0, replace = False, n_samples = values_1.shape[0])\n",
    "\n",
    "#     train_features = pd.concat([values_0, values_1])\n",
    "    \n",
    "#     labels = np.repeat([0,1], values_0.shape[0])\n",
    "    \n",
    "    #clf = BaggingClassifier(SVC(kernel = 'poly', degree = 5, class_weight = 'balanced', verbose = True, C = 10))\n",
    "    clf_w = SVC(kernel = 'rbf', class_weight = 'balanced', verbose = 2)\n",
    "    \n",
    "    parameters = {'C':(0.1, 1, 10, 20)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 5,\n",
    "                                        refit = True, scoring = 'roc_auc', verbose = 2,\n",
    "                                       n_jobs=6, return_train_score = True)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "#     clf.fit(train_features, labels)\n",
    "    \n",
    "#     print(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "    # compute probabilites as opposed to predictions\n",
    "    #dual_coefficients = clf.dual_coef_    # do we have to normalize with norm of this vector ?\n",
    "    \n",
    "    distance_hyperplane = clf.decision_function(test_features)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplane[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "    columns_1.append(probability)\n",
    "\n",
    "    \n",
    "    distance_hyperplace_train = clf.decision_function(train_features)\n",
    "    probability = np.empty(len(distance_hyperplace_train))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplace_train[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplace_train[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplace_train[j]))\n",
    "    \n",
    "    tmp = roc_auc_score(y_score= probability, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels that have a real value\n",
    "columns_2 = []\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "for i in range(12, 16):\n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param =80)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "#     print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    clf_w = SVR(kernel = 'rbf', cache_size = 6000)\n",
    "# #     clf_w = NuSVR(nu=0.5, kernel = 'linear')\n",
    "    parameters = {'C':(0.1, 1,10, 20)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 10,\n",
    "                                       refit = True, scoring = 'r2', verbose = 2, n_jobs=6)\n",
    "#     clf = KernelRidge(kernel = 'poly', degree = 5)\n",
    "#     parameters = {'alpha':(0.1,1,10,30)}\n",
    "#     clf = model_selection.GridSearchCV(estimator= clf, param_grid = parameters, cv = 3,\n",
    "#                                       refit = True, scoring = 'r2', verbose = 2, n_jobs=6)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "#     print(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "\n",
    "    pred_train = clf.predict(train_features)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    \n",
    "    pred = clf.predict(test_features)\n",
    "    columns_2.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with Support vector regression and then compute sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "\n",
    "# columns_1 = [test_pids]\n",
    "\n",
    "# for i in range(1,12):\n",
    "    \n",
    "#     clf = SVR(kernel = 'poly', degree = 3, max_iter = 10000)\n",
    "#     clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "#     pred = clf.predict(data_test_scaled)\n",
    "#     prob = np.empty(len(pred))\n",
    "#     for j in range(0, len(pred)):\n",
    "#         prob[j] = 1 / (1 + math.exp(-pred[j]))\n",
    "#     columns_1.append(prob)\n",
    "    \n",
    "#     pred_train = clf.predict(data_train_scaled)\n",
    "#     prob_train = np.empty(len(pred_train))\n",
    "#     for j in range(0, len(pred_train)):\n",
    "#         prob_train[j] = 1 / (1 + math.exp(-pred_train[j]))    \n",
    "#     tmp = roc_auc_score(y_score= prob_train, y_true= df_train_labels.iloc[:,i])\n",
    "#     print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "/usr/local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "0.4272675402863789\n",
      "R2 for feature LABEL_RRate  :  0.43301788996082624\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "0.5976017817154319\n",
      "R2 for feature LABEL_ABPm  :  0.6193099863826221\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 out of  40 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.2990090520477443\n",
      "R2 for feature LABEL_SpO2  :  0.41787686694537984\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=6)]: Done  80 out of  80 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "0.6153758143241128\n",
      "R2 for feature LABEL_Heartrate  :  0.6554719255181802\n"
     ]
    }
   ],
   "source": [
    "#labels that have a real value\n",
    "\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "    \n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param=80)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "#     print(list(data_train_scaled)[transformer.get_support()])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    if(i == 14):\n",
    "        clf_w = SVR(kernel = 'rbf', cache_size = 6000)\n",
    "        parameters = {'C':(0.1, 1,10, 20)}\n",
    "    else:\n",
    "        clf_w = LinearSVR()\n",
    "        parameters = {'C':(0.01, 0.1,1,10,30,50, 75,100)}\n",
    "        \n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 10,\n",
    "                                       refit = True, scoring = 'r2', verbose = 1, n_jobs=6)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "    \n",
    "    pred = clf.predict(test_features)\n",
    "    columns_2.append(pred)\n",
    "    \n",
    "    pred_train = clf.predict(train_features)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param=20)\n",
    "train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,11])\n",
    "test_features = transformer.transform(data_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_agg_features.columns[transformer.get_support(indices = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest Classifier\n",
    "columns_1 = [test_pids]\n",
    "for i in range(1, 12):\n",
    "    clf = RandomForestClassifier(min_samples_leaf=2, class_weight='balanced', oob_score=False, bootstrap=False)\n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(clf.oob_score)\n",
    "    # compute probabilites as opposed to predictions\n",
    "    probability = clf.apply(data_test_scaled)\n",
    "    probs = [i[1] for i in probability] \n",
    "    columns_1.append(probs)\n",
    "    \n",
    "    \n",
    "    probability = clf.predict_proba(data_train_scaled)\n",
    "\n",
    "    probs = [i[1] for i in probability]            \n",
    "    tmp = roc_auc_score(y_score= probs, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernelized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=6)]: Done  70 out of  70 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6626445  0.69937407 0.73216233 0.7475475  0.75114156 0.75327248\n",
      " 0.75441509]\n",
      "[0.65299292 0.67255175 0.67248679 0.66760654 0.65922669 0.65823246\n",
      " 0.65261516]\n",
      "{'base_estimator__C': 0.1}\n",
      "0.6725517455777675\n",
      "ROC AUC for feature LABEL_Sepsis  :  0.6980688520591686\n",
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  3.1min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-bf8305155cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                         \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                        n_jobs=6, return_train_score = True)\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_train_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "for i in range(1, 12):\n",
    "    i = 11\n",
    "    #     feature selection\n",
    "#     transformer =  GenericUnivariateSelect(score_func= mutual_info_classif, mode ='k_best', param = 80)\n",
    "#     train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "# #     print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "#     test_features = transformer.transform(data_test_scaled)\n",
    "\n",
    "    feature_map_nystroem = Nystroem(kernel = 'rbf',\n",
    "                                 random_state=1,\n",
    "                                 n_components=350)\n",
    "    \n",
    "    train_transformed = feature_map_nystroem.fit_transform(data_train_scaled)\n",
    "    test_transformed = feature_map_nystroem.transform(data_test_scaled)\n",
    "    \n",
    "    clf_w = LogisticRegression(penalty = 'l2', class_weight = 'balanced', max_iter=10000)\n",
    "    \n",
    "    # checked before\n",
    "    #parameters = {'alpha':(0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 20, 30)}\n",
    "    parameters = {'C':(0.01, 0.1, 1, 5, 10, 20, 30)}\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle = True, random_state = 1)\n",
    "    \n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = skf,\n",
    "                                        refit = True, scoring = 'roc_auc', verbose = 1,\n",
    "                                       n_jobs=6, return_train_score = True)\n",
    "    clf.fit(train_transformed, df_train_labels.iloc[:,i])\n",
    "    \n",
    "    print(clf.cv_results_['mean_train_score'])\n",
    "    print(clf.cv_results_['mean_test_score'])\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    " \n",
    "    probability_tmp = clf.predict_proba(test_transformed)\n",
    "    probability = [item[1] for item in probability_tmp]\n",
    "    columns_1.append(probability)\n",
    "\n",
    "    probability_tmp = clf.predict_proba(train_transformed)\n",
    "    probability_train = [item[1] for item in probability_tmp]\n",
    "    tmp = roc_auc_score(y_score= probability_train, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the kernel and use SGD Classifier and Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "for i in range(1, 12):\n",
    "   \n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_classif, mode ='k_best', param=70)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(\"For feature \", df_train_labels.columns[i])\n",
    "#     print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "\n",
    "    \n",
    "    feature_map_nystroem = Nystroem(kernel = 'poly', degree = 3,\n",
    "                                 random_state=1,\n",
    "                                 n_components=300)\n",
    "    train_transformed = feature_map_nystroem.fit_transform(train_features)\n",
    "    test_transformed = feature_map_nystroem.transform(test_features)\n",
    "    \n",
    "    clf_w = linear_model.SGDClassifier(max_iter=100000, tol=1e-4, penalty = \"l2\", \n",
    "                                       loss = \"epsilon_insensitive\", class_weight='balanced')\n",
    "    # checked before\n",
    "    #parameters = {'alpha':(0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 20, 30)}\n",
    "    parameters = {'alpha':(0.1, 1, 5, 10)}\n",
    "    \n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 10,\n",
    "                                        refit = True, scoring = 'roc_auc', verbose = 1,\n",
    "                                       n_jobs=6, return_train_score = True)\n",
    "    clf.fit(train_transformed, df_train_labels.iloc[:,i])\n",
    "    \n",
    "#     print(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "    # compute probabilites as opposed to predictions\n",
    "    #dual_coefficients = clf.dual_coef_    # do we have to normalize with norm of this vector ?\n",
    "    \n",
    "    distance_hyperplane = clf.decision_function(test_transformed)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplane[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "    columns_1.append(probability)\n",
    "\n",
    "    \n",
    "    distance_hyperplace_train = clf.decision_function(train_transformed)\n",
    "    probability = np.empty(len(distance_hyperplace_train))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplace_train[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplace_train[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplace_train[j]))\n",
    "    \n",
    "    tmp = roc_auc_score(y_score= probability, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels that have a real value\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "#     feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param = 40)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "#     print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    feature_map_nystroem = Nystroem(kernel = 'rbf',\n",
    "                                 random_state=1,\n",
    "                                 n_components=200)\n",
    "    train_features = feature_map_nystroem.fit_transform(train_features)\n",
    "    test_features = feature_map_nystroem.transform(test_features)\n",
    "    \n",
    "    clf_w = linear_model.SGDRegressor(max_iter=100000, tol=1e-4,\n",
    "                                     loss = 'epsilon_insensitive', penalty = 'l2')\n",
    "    parameters = {'alpha':(0.0001, 0.001, 0.01, 0.1, 1, 5, 10)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 10,\n",
    "                                       refit = True, scoring = 'r2', verbose = 1, n_jobs=6, return_train_score=True)\n",
    "#     clf = KernelRidge(kernel = 'poly', degree = 5)\n",
    "#     parameters = {'alpha':(0.1,1,10,30)}\n",
    "#     clf = model_selection.GridSearchCV(estimator= clf, param_grid = parameters, cv = 3,\n",
    "#                                       refit = True, scoring = 'r2', verbose = 2, n_jobs=6)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "#     print(clf.cv_results_)\n",
    "    print(clf.cv_results_['mean_train_score'])\n",
    "    print(clf.cv_results_['mean_test_score'])\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "    \n",
    "    pred = clf.predict(test_features)\n",
    "    columns_2.append(pred) \n",
    "\n",
    "    pred_train = clf.predict(train_features)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of XGBoost is that it accepts missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# simple example\n",
    "# load file from text file, also binary buffer generated by xgboost\n",
    "\n",
    "# scale test data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "df_train_scaled_xgboost = min_max_scaler.fit_transform(df_train_agg_features)\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "df_test_scaled_xgboost = min_max_scaler.fit_transform(df_test_agg_features)\n",
    "\n",
    "dtrain = xgb.DMatrix(df_train_scaled_xgboost, label=df_train_labels.iloc[:,1])\n",
    "dtest = xgb.DMatrix(df_test_scaled_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'eta': 1, 'objective': 'binary:logistic', 'verbosity':1}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist = [(dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 10\n",
    "xgb.cv(param, dtrain, num_round, nfold=10,\n",
    "       metrics={'auc'}, seed=0,\n",
    "       callbacks=[xgb.callback.print_evaluation(show_stdv=True)])\n",
    "# bst = xgb.train(param, dtrain, num_round)\n",
    "# pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 out of  40 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4}\n",
      "0.9021221528886334\n",
      "ROC AUC for feature LABEL_BaseExcess  :  0.8789192323561444\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 out of  40 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2}\n",
      "0.7655657229886372\n",
      "ROC AUC for feature LABEL_Fibrinogen  :  0.6207097186700767\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  40 out of  40 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2}\n",
      "0.7111729556295098\n",
      "ROC AUC for feature LABEL_AST  :  0.5960129151503049\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9518a40fde98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mclf_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "\n",
    "for i in range(1,12):\n",
    "\n",
    "    clf = xgb.XGBClassifier('binary:logistic')\n",
    "    \n",
    "    clf_w = model_selection.GridSearchCV(estimator= clf, param_grid = {'max_depth': [2,3,4,5]}, cv = 10,\n",
    "                                        refit = True, scoring = 'roc_auc', verbose = 1,\n",
    "                                       n_jobs=6, return_train_score = True)\n",
    "    \n",
    "\n",
    "    clf_w.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(clf_w.best_params_)\n",
    "    print(clf_w.best_score_) \n",
    "#     dtrain = xgb.DMatrix(df_train_agg_features, label=df_train_labels.iloc[:,i])\n",
    "#     num_round = 10\n",
    "#     xgb.cv(param, dtrain, num_round, nfold=10,\n",
    "#        metrics={'auc'}, seed=0,\n",
    "#        callbacks=[xgb.callback.print_evaluation(show_stdv=True)])\n",
    "    \n",
    "    probability = clf_w.predict(data_test_scaled)\n",
    "    columns_1.append(probability)\n",
    "\n",
    "    probability_train = clf_w.predict(data_train_scaled)\n",
    "#     probability_train = [item[1] for item in probability_tmp]\n",
    "    tmp = roc_auc_score(y_score= probability_train, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  30 out of  30 | elapsed:   51.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "0.4200176924297615\n",
      "R2 for feature LABEL_RRate  :  0.5392544663130121\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  30 out of  30 | elapsed:   54.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "0.6144187790982285\n",
      "R2 for feature LABEL_ABPm  :  0.6863046639629317\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  30 out of  30 | elapsed:   53.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "0.3421986139455796\n",
      "R2 for feature LABEL_SpO2  :  0.607600007016429\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  30 out of  30 | elapsed:   54.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "0.6576084499489625\n",
      "R2 for feature LABEL_Heartrate  :  0.7175087922391096\n"
     ]
    }
   ],
   "source": [
    "columns_2_1 = []\n",
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'reg:squarederror', 'verbosity':1}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'rmse'\n",
    "# evallist = [(dtrain, 'train')]\n",
    "\n",
    "train_features = data_train_scaled\n",
    "test_features = data_test_scaled\n",
    "for i in range(12,16):\n",
    "#     transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param=80)\n",
    "#     train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "# #     print(list(data_train_scaled)[transformer.get_support()])\n",
    "#     test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    clf_w = xgb.XGBRegressor(feval = r2_score, verbosity = 0)\n",
    "            \n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = {'max_depth':(3,4,5)}, cv = 10,\n",
    "                                       refit = True, verbose = 1, scoring='r2',\n",
    "                                       n_jobs=6, return_train_score = True)\n",
    "    \n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)    \n",
    "    \n",
    "#     dtrain = xgb.DMatrix(df_train_scaled_xgboost, label=df_train_labels.iloc[:,i])\n",
    "#     num_round = 10\n",
    "    \n",
    "    probability = clf.predict(test_features)\n",
    "    columns_2_1.append(probability)\n",
    "\n",
    "    pred_train = clf.predict(train_features)\n",
    "#     probability_train = [item[1] for item in probability_tmp]\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 12664)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(columns_final))\n",
    "result = pd.DataFrame(columns_final).transpose()\n",
    "result.columns = list(df_train_labels)\n",
    "result.to_csv('./Results/prediction.csv.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./Results/prediction.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
