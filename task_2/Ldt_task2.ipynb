{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, mutual_info_classif, mutual_info_regression, f_regression\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "\n",
    "# load data from csv file\n",
    "df_train_features = pd.read_csv ('train_features.csv')\n",
    "df_train_labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "# Load test data\n",
    "df_test_features = pd.read_csv ('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels = df_train_labels.sort_values(by = 'pid')\n",
    "df_train_features = df_train_features.sort_values(by = 'pid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Histogram of the output labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels.hist()\n",
    "\n",
    "# with PdfPages(\"./Results/Labels_histogram.pdf\") as export_pdf:\n",
    "#     for i in list(df_train_labels)[1:]:\n",
    "#         df_train_labels.hist(column = i, bins = 100)\n",
    "#         export_pdf.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see the class imbalance problem here. Other observations:\n",
    "  * Heartrate, RRate, ABPm,  distribution is similar to a normal distribution\n",
    "  * SpO2 is like a censored normal distribution. \n",
    "  * For all of the other features, class imbalance is an obvious problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic strategy that could be used here: Upsample both classes! Do the upsampling efficiently, not just replicating the datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data inspection: \n",
    "#############################################\n",
    "# range of the provided data?\n",
    "print(df_train_features.agg([min, max]))\n",
    "\n",
    "# Boxplotting the data\n",
    "# fig2, ax2 = plt.subplots()\n",
    "# ax2.set_title('BUN')\n",
    "# ax2.boxplot(df_train_features.iloc[:,5], notch=True)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.boxplot(data = df_train_features.iloc[:,1:])\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "\n",
    "# with PdfPages(\"./Results/Train_columns_boxplot.pdf\") as export_pdf:\n",
    "#     for i in list(df_train_labels)[1:]:\n",
    "#         df_train_labels.hist(column = i, bins = 100)\n",
    "#         export_pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix\n",
    "corr = df_train_features.corr()\n",
    "\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns, \n",
    "        vmin=-1, vmax=1, center=0, \n",
    "           cmap=sns.diverging_palette(20, 220, n=200))\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing pattern of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much missing data? \n",
    "print(\"Percentage of missing values:\")\n",
    "print(df_train_features.isnull().sum(axis=0) / len(df_train_features))\n",
    "\n",
    "msno.matrix(df_train_features)\n",
    "\n",
    "# Plotting the correlation between the missing values\n",
    "msno.heatmap(df_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_agg_features = df_train_features.groupby('pid').agg([np.min, np.max, np.mean])\n",
    "df_train_agg_features = df_train_agg_features.iloc[:,5:]\n",
    "# Removing ETCo2 mean and max since it has so many NA\n",
    "df_train_agg_features = df_train_agg_features.drop(df_train_agg_features.columns[[2,3]],  axis = 1)\n",
    "print(df_train_agg_features.columns)\n",
    "df_train_agg_features.columns\n",
    "print(int(df_train_agg_features.shape[1]))\n",
    "print(int(df_train_agg_features.shape[1]/3))\n",
    "\n",
    "# how much missing data? \n",
    "print(\"number of missing values:\")\n",
    "print(df_train_agg_features.isnull().sum(axis=0))\n",
    "\n",
    "na_percent_max = int(0.8 * df_train_agg_features.shape[0])\n",
    "tmp = pd.DataFrame(df_train_agg_features)\n",
    "for i in range(1, (int(df_train_agg_features.shape[1]/3))):\n",
    "    na_count = df_train_agg_features.iloc[:,i].isna().sum()\n",
    "    print(df_train_agg_features.columns[i])\n",
    "    print(na_count)\n",
    "    \n",
    "    if(na_count > na_percent_max):\n",
    "        print(\"should be removed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "#imp = SimpleImputer(strategy=\"mean\")\n",
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "#imputer = IterativeImputer(random_state=0, verbose = 2, max_iter = 30)\n",
    "df_train_agg_imputed_features = imputer.fit_transform(df_train_agg_features)\n",
    "#print(df_train_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "# standard_scalar = preprocessing.StandardScaler()\n",
    "\n",
    "data_train_scaled = min_max_scaler.fit_transform(df_train_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REARRANGE THE LABELS, TO MATCH THE REARRANGED FEATURES\n",
    "df_train_labels_sorted = df_train_labels.sort_values(by = 'pid')\n",
    "print(df_train_labels_sorted[['pid']])\n",
    "print(df_train_labels[['pid']])\n",
    "print(df_train_agg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the training data after imputing and aggregating\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "ax = sns.boxplot(data = pd.DataFrame(data_train_scaled))\n",
    "ax.set_xticklabels(\n",
    "    list(df_train_features),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the correlation between the \n",
    "pd.DataFrame(data_train_scaled).corrwith(other = pd.DataFrame(df_train_agg_imputed_features), method = \"spearman\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(data_train_scaled)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "finalDf = pd.concat([principalDf, df_train_labels[[df_train_labels.columns[11]]]], axis = 1)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA for label i', fontsize = 20)\n",
    "targets = [0, 1]\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf[df_train_labels.columns[11]] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data inspection: \n",
    "#############################################\n",
    "# range of the provided data?\n",
    "print(df_test_features.agg([min, max]))\n",
    "\n",
    "# how much missing data? \n",
    "print(\"number of missing values:\")\n",
    "print(df_test_features.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aggregate data for each pid\n",
    "# df_test_aggregate_features = df_test_features.groupby('pid').agg('median')\n",
    "\n",
    "df_test_agg_features = df_test_features.groupby('pid').agg([np.min, np.max, np.mean])\n",
    "\n",
    "df_test_agg_features = df_test_agg_features.iloc[:,5:]\n",
    "# Removing ETCo2 mean and max since it has so many NA\n",
    "df_test_agg_features = df_test_agg_features.drop(df_test_agg_features.columns[[2,3]],  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "# should we impute it with the same imputer that we've used for train?\n",
    "\n",
    "imputer = KNNImputer(n_neighbors= 10)\n",
    "#imputer = IterativeImputer(random_state=0, verbose = 1)\n",
    "df_test_agg_imputed_features = imputer.fit_transform(df_test_agg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale test data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "data_test_scaled = min_max_scaler.fit_transform(df_test_agg_imputed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data_train_scaled).to_csv(\"./Results/4stats_iterarive_dat_train_scaled.csv\")\n",
    "# pd.DataFrame(data_test_scaled).to_csv(\"./Results/4stats_iterative_dat_test_scaled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with support vector machine classification and use probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature  LABEL_BaseExcess\n",
      "MultiIndex([(       'PTT', 'amin'),\n",
      "            (       'PTT', 'amax'),\n",
      "            (       'PTT', 'mean'),\n",
      "            (   'Lactate', 'amin'),\n",
      "            (   'Lactate', 'amax'),\n",
      "            (   'Lactate', 'mean'),\n",
      "            (      'Temp', 'mean'),\n",
      "            (       'Hgb', 'mean'),\n",
      "            (      'HCO3', 'amin'),\n",
      "            (      'HCO3', 'amax'),\n",
      "            (      'HCO3', 'mean'),\n",
      "            ('BaseExcess', 'amin'),\n",
      "            ('BaseExcess', 'amax'),\n",
      "            ('BaseExcess', 'mean'),\n",
      "            (     'RRate', 'mean'),\n",
      "            ('Creatinine', 'amin'),\n",
      "            ('Creatinine', 'amax'),\n",
      "            ('Creatinine', 'mean'),\n",
      "            (     'PaCO2', 'amin'),\n",
      "            (     'PaCO2', 'amax'),\n",
      "            (     'PaCO2', 'mean'),\n",
      "            (      'FiO2', 'amin'),\n",
      "            (      'FiO2', 'amax'),\n",
      "            (      'FiO2', 'mean'),\n",
      "            (      'SaO2', 'amin'),\n",
      "            (      'SaO2', 'amax'),\n",
      "            (      'SaO2', 'mean'),\n",
      "            (      'ABPm', 'mean'),\n",
      "            (      'ABPd', 'mean'),\n",
      "            (   'Calcium', 'amin'),\n",
      "            (   'Calcium', 'amax'),\n",
      "            (   'Calcium', 'mean'),\n",
      "            (  'Chloride', 'amin'),\n",
      "            (  'Chloride', 'amax'),\n",
      "            (  'Chloride', 'mean'),\n",
      "            (       'Hct', 'amax'),\n",
      "            (      'ABPs', 'mean'),\n",
      "            (        'pH', 'amin'),\n",
      "            (        'pH', 'amax'),\n",
      "            (        'pH', 'mean')],\n",
      "           )\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-87eea5060d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                         \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                        n_jobs=6, return_train_score = True)\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "test_pids = list(set(df_test_features.pid))\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "for i in range(1, 12):\n",
    "   \n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_classif, mode ='k_best', param=40)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(\"For feature \", df_train_labels.columns[i])\n",
    "    print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "\n",
    "    \n",
    "    #clf = BaggingClassifier(SVC(kernel = 'poly', degree = 5, class_weight = 'balanced', verbose = True, C = 10))\n",
    "    clf_w = SVC(kernel = 'poly', degree = 3, class_weight = 'balanced', verbose = 2)\n",
    "    \n",
    "    parameters = {'C':(0.1, 1, 5, 10)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 5,\n",
    "                                        refit = True, scoring = 'roc_auc', verbose = 2,\n",
    "                                       n_jobs=6, return_train_score = True)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "    print(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "    # compute probabilites as opposed to predictions\n",
    "    #dual_coefficients = clf.dual_coef_    # do we have to normalize with norm of this vector ?\n",
    "    \n",
    "    distance_hyperplane = clf.decision_function(test_features)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplane[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "    columns_1.append(probability)\n",
    "\n",
    "    \n",
    "    distance_hyperplace_train = clf.decision_function(train_features)\n",
    "    probability = np.empty(len(distance_hyperplace_train))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplace_train[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplace_train[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplace_train[j]))\n",
    "    \n",
    "    tmp = roc_auc_score(y_score= probability, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([22.40885172, 22.84809146, 21.25310478]), 'std_fit_time': array([0.06816745, 0.13452873, 3.31278865]), 'mean_score_time': array([4.55382714, 4.49709716, 3.69804029]), 'std_score_time': array([0.01893634, 0.04048154, 0.52262203]), 'param_C': masked_array(data=[0.1, 1, 10],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.1}, {'C': 1}, {'C': 10}], 'split0_test_score': array([0.52470667, 0.57949584, 0.60073112]), 'split1_test_score': array([0.51697736, 0.57453686, 0.60189326]), 'split2_test_score': array([0.53313793, 0.58945065, 0.60719138]), 'split3_test_score': array([0.52378756, 0.58424314, 0.61198652]), 'split4_test_score': array([0.51733216, 0.56972221, 0.58543835]), 'mean_test_score': array([0.52318833, 0.57948974, 0.60144813]), 'std_test_score': array([0.00590813, 0.00695342, 0.0089562 ]), 'rank_test_score': array([3, 2, 1], dtype=int32)}\n",
      "{'C': 10}\n",
      "0.6014481277020215\n",
      "R2 for feature LABEL_Heartrate  :  0.6959475560817752\n"
     ]
    }
   ],
   "source": [
    "# labels that have a real value\n",
    "columns_2 = []\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "for i in range(12, 16):\n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param = 50)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    clf_w = SVR(kernel = 'rbf', gamma = 'scale', cache_size = 6000)\n",
    "# #     clf_w = NuSVR(nu=0.5, kernel = 'linear')\n",
    "    parameters = {'C':(0.1, 1,10)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 5,\n",
    "                                       refit = True, scoring = 'r2', verbose = 2, n_jobs=6)\n",
    "#     clf = KernelRidge(kernel = 'poly', degree = 5)\n",
    "#     parameters = {'alpha':(0.1,1,10,30)}\n",
    "#     clf = model_selection.GridSearchCV(estimator= clf, param_grid = parameters, cv = 3,\n",
    "#                                       refit = True, scoring = 'r2', verbose = 2, n_jobs=6)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "    print(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "\n",
    "    pred_train = clf.predict(train_features)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    \n",
    "    pred = clf.predict(test_features)\n",
    "    columns_2.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict with Support vector regression and then compute sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "\n",
    "# columns_1 = [test_pids]\n",
    "\n",
    "# for i in range(1,12):\n",
    "    \n",
    "#     clf = SVR(kernel = 'poly', degree = 3, max_iter = 10000)\n",
    "#     clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "#     pred = clf.predict(data_test_scaled)\n",
    "#     prob = np.empty(len(pred))\n",
    "#     for j in range(0, len(pred)):\n",
    "#         prob[j] = 1 / (1 + math.exp(-pred[j]))\n",
    "#     columns_1.append(prob)\n",
    "    \n",
    "#     pred_train = clf.predict(data_train_scaled)\n",
    "#     prob_train = np.empty(len(pred_train))\n",
    "#     for j in range(0, len(pred_train)):\n",
    "#         prob_train[j] = 1 / (1 + math.exp(-pred_train[j]))    \n",
    "#     tmp = roc_auc_score(y_score= prob_train, y_true= df_train_labels.iloc[:,i])\n",
    "#     print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #labels that have a real value\n",
    "\n",
    "# columns_2 = []\n",
    "\n",
    "# for i in range(12, 16):\n",
    "    \n",
    "#     # feature selection\n",
    "#     transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param=20)\n",
    "#     train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "#     print(list(data_train_scaled)[transformer.get_support()])\n",
    "#     test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "\n",
    "#     clf_w = LinearSVR()\n",
    "#     parameters = {'C':(0.1,1,10,30,60,100)}\n",
    "#     clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 2,\n",
    "#                                        refit = True, scoring = 'r2', verbose = 1, n_jobs=6)\n",
    "#     clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "#     print(clf.cv_results_)\n",
    "#     pred = clf.predict(test_features)\n",
    "#     columns_2.append(pred)\n",
    "    \n",
    "#     pred_train = clf.predict(train_features)\n",
    "#     tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "#     print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param=20)\n",
    "train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,11])\n",
    "test_features = transformer.transform(data_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_agg_features.columns[transformer.get_support(indices = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest Classifier\n",
    "columns_1 = [test_pids]\n",
    "for i in range(1, 12):\n",
    "    clf = RandomForestClassifier(min_samples_leaf=2, class_weight='balanced', oob_score=False, bootstrap=False)\n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(clf.oob_score)\n",
    "    # compute probabilites as opposed to predictions\n",
    "    probability = clf.apply(data_test_scaled)\n",
    "    probs = [i[1] for i in probability] \n",
    "    columns_1.append(probs)\n",
    "    \n",
    "    \n",
    "    probability = clf.predict_proba(data_train_scaled)\n",
    "\n",
    "    probs = [i[1] for i in probability]            \n",
    "    tmp = roc_auc_score(y_score= probs, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the kernel and use SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature  LABEL_BaseExcess\n",
      "MultiIndex([(       'PTT', 'amin'),\n",
      "            (       'PTT', 'amax'),\n",
      "            (       'PTT', 'mean'),\n",
      "            (   'Lactate', 'amin'),\n",
      "            (   'Lactate', 'amax'),\n",
      "            (   'Lactate', 'mean'),\n",
      "            (      'Temp', 'mean'),\n",
      "            (      'HCO3', 'amin'),\n",
      "            (      'HCO3', 'amax'),\n",
      "            (      'HCO3', 'mean'),\n",
      "            ('BaseExcess', 'amin'),\n",
      "            ('BaseExcess', 'amax'),\n",
      "            ('BaseExcess', 'mean'),\n",
      "            (     'RRate', 'mean'),\n",
      "            ('Creatinine', 'amin'),\n",
      "            ('Creatinine', 'amax'),\n",
      "            ('Creatinine', 'mean'),\n",
      "            (     'PaCO2', 'amin'),\n",
      "            (     'PaCO2', 'amax'),\n",
      "            (     'PaCO2', 'mean'),\n",
      "            (      'FiO2', 'amin'),\n",
      "            (      'FiO2', 'amax'),\n",
      "            (      'FiO2', 'mean'),\n",
      "            (      'SaO2', 'amin'),\n",
      "            (      'SaO2', 'amax'),\n",
      "            (      'SaO2', 'mean'),\n",
      "            (      'ABPm', 'mean'),\n",
      "            (      'ABPd', 'mean'),\n",
      "            (   'Calcium', 'amin'),\n",
      "            (   'Calcium', 'amax'),\n",
      "            (      'SpO2', 'mean'),\n",
      "            (  'Chloride', 'amin'),\n",
      "            (  'Chloride', 'amax'),\n",
      "            (  'Chloride', 'mean'),\n",
      "            (       'Hct', 'amin'),\n",
      "            (       'Hct', 'amax'),\n",
      "            (      'ABPs', 'mean'),\n",
      "            (        'pH', 'amin'),\n",
      "            (        'pH', 'amax'),\n",
      "            (        'pH', 'mean')],\n",
      "           )\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  14 out of  25 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done  25 out of  25 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.11057463, 0.07374015, 0.03751969, 0.25193596, 0.09882545]), 'std_fit_time': array([0.0212206 , 0.01043428, 0.00273282, 0.26721602, 0.01219469]), 'mean_score_time': array([0.00421042, 0.00273509, 0.00318069, 0.00328465, 0.00259871]), 'std_score_time': array([0.00108714, 0.00036793, 0.00073961, 0.00147451, 0.00041033]), 'param_alpha': masked_array(data=[0.01, 0.1, 1, 10, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 100}], 'split0_test_score': array([0.70357478, 0.70297928, 0.7140497 , 0.67020546, 0.66995745]), 'split1_test_score': array([0.70395719, 0.70355653, 0.71282644, 0.71324616, 0.66275019]), 'split2_test_score': array([0.71137806, 0.71463771, 0.72318679, 0.72180407, 0.68508624]), 'split3_test_score': array([0.70147662, 0.71040553, 0.7170685 , 0.66053014, 0.66038612]), 'split4_test_score': array([0.6856454 , 0.6892464 , 0.70828079, 0.70788896, 0.67488086]), 'mean_test_score': array([0.70120641, 0.70416509, 0.71508245, 0.69473496, 0.67061217]), 'std_test_score': array([0.00847179, 0.0086367 , 0.00494051, 0.0245768 , 0.00888293]), 'rank_test_score': array([3, 2, 1, 4, 5], dtype=int32), 'split0_train_score': array([0.70877107, 0.70802765, 0.71806069, 0.67150821, 0.67128001]), 'split1_train_score': array([0.70756443, 0.70872477, 0.71765184, 0.7181277 , 0.67299354]), 'split2_train_score': array([0.69538396, 0.70093112, 0.71404495, 0.7119689 , 0.66864685]), 'split3_train_score': array([0.69829004, 0.70462799, 0.71434116, 0.67318676, 0.67304631]), 'split4_train_score': array([0.7060553 , 0.70753502, 0.71850062, 0.71855395, 0.67090364]), 'mean_train_score': array([0.70321296, 0.70596931, 0.71651985, 0.6986691 , 0.67137407]), 'std_train_score': array([0.00535603, 0.0028797 , 0.00192098, 0.02162403, 0.00161784])}\n",
      "{'alpha': 1}\n",
      "0.7150824459391807\n",
      "ROC AUC for feature LABEL_BaseExcess  :  0.7171241863395976\n",
      "For feature  LABEL_Fibrinogen\n",
      "MultiIndex([(             'PTT', 'amin'),\n",
      "            (             'PTT', 'amax'),\n",
      "            (             'PTT', 'mean'),\n",
      "            (         'Lactate', 'amin'),\n",
      "            (         'Lactate', 'amax'),\n",
      "            (         'Lactate', 'mean'),\n",
      "            (             'Hgb', 'amin'),\n",
      "            (             'Hgb', 'amax'),\n",
      "            (             'Hgb', 'mean'),\n",
      "            (      'Fibrinogen', 'amin'),\n",
      "            (      'Fibrinogen', 'amax'),\n",
      "            (      'Fibrinogen', 'mean'),\n",
      "            (             'WBC', 'amin'),\n",
      "            (             'WBC', 'amax'),\n",
      "            (             'WBC', 'mean'),\n",
      "            (      'Creatinine', 'amin'),\n",
      "            (      'Creatinine', 'amax'),\n",
      "            (           'PaCO2', 'amin'),\n",
      "            (             'AST', 'amin'),\n",
      "            (             'AST', 'amax'),\n",
      "            (             'AST', 'mean'),\n",
      "            (       'Platelets', 'amin'),\n",
      "            (       'Platelets', 'amax'),\n",
      "            (       'Platelets', 'mean'),\n",
      "            (         'Glucose', 'amax'),\n",
      "            (         'Calcium', 'amin'),\n",
      "            (    'Alkalinephos', 'amin'),\n",
      "            (    'Alkalinephos', 'amax'),\n",
      "            (    'Alkalinephos', 'mean'),\n",
      "            ('Bilirubin_direct', 'amin'),\n",
      "            ('Bilirubin_direct', 'amax'),\n",
      "            ('Bilirubin_direct', 'mean'),\n",
      "            (        'Chloride', 'mean'),\n",
      "            (             'Hct', 'amin'),\n",
      "            (             'Hct', 'amax'),\n",
      "            (             'Hct', 'mean'),\n",
      "            ( 'Bilirubin_total', 'amin'),\n",
      "            ( 'Bilirubin_total', 'amax'),\n",
      "            ( 'Bilirubin_total', 'mean'),\n",
      "            (              'pH', 'mean')],\n",
      "           )\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  14 out of  25 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done  25 out of  25 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.10159826, 0.04708314, 0.03299627, 0.34768395, 0.2233634 ]), 'std_fit_time': array([0.00504395, 0.00193413, 0.00361055, 0.64637971, 0.02210923]), 'mean_score_time': array([0.00320454, 0.00316663, 0.00269694, 0.00245242, 0.00243545]), 'std_score_time': array([0.00061056, 0.00057083, 0.00034025, 0.00041285, 0.00013181]), 'param_alpha': masked_array(data=[0.01, 0.1, 1, 10, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 100}], 'split0_test_score': array([0.59279422, 0.55817704, 0.60573113, 0.68418889, 0.67857955]), 'split1_test_score': array([0.65899403, 0.64241363, 0.6085901 , 0.69960013, 0.70004263]), 'split2_test_score': array([0.62161024, 0.58402955, 0.60961718, 0.62044615, 0.67995372]), 'split3_test_score': array([0.63193683, 0.63661044, 0.64354423, 0.70318171, 0.70337657]), 'split4_test_score': array([0.58730971, 0.5350069 , 0.63977794, 0.56392035, 0.67172898]), 'mean_test_score': array([0.61852901, 0.59124751, 0.62145212, 0.65426745, 0.68673629]), 'std_test_score': array([0.0263196 , 0.04238992, 0.01659243, 0.05412842, 0.01258342]), 'rank_test_score': array([4, 5, 3, 2, 1], dtype=int32), 'split0_train_score': array([0.60856245, 0.58012682, 0.61104755, 0.68315116, 0.68921937]), 'split1_train_score': array([0.6512744 , 0.63979183, 0.58346705, 0.69577415, 0.68443761]), 'split2_train_score': array([0.64474587, 0.58490421, 0.62302361, 0.62390048, 0.68922076]), 'split3_train_score': array([0.5984238 , 0.62392484, 0.61390887, 0.68224257, 0.68229617]), 'split4_train_score': array([0.62887717, 0.57412313, 0.6785366 , 0.5929129 , 0.69240627]), 'mean_train_score': array([0.62637674, 0.60057417, 0.62199674, 0.65559625, 0.68751604]), 'std_train_score': array([0.02030904, 0.02625482, 0.03120143, 0.04004344, 0.00364542])}\n",
      "{'alpha': 100}\n",
      "0.6867362887183859\n",
      "ROC AUC for feature LABEL_Fibrinogen  :  0.6874445256363415\n",
      "For feature  LABEL_AST\n",
      "MultiIndex([(             'PTT', 'amin'),\n",
      "            (             'PTT', 'amax'),\n",
      "            (             'BUN', 'amax'),\n",
      "            (             'BUN', 'mean'),\n",
      "            (            'Temp', 'mean'),\n",
      "            (             'Hgb', 'mean'),\n",
      "            (            'HCO3', 'amax'),\n",
      "            (            'HCO3', 'mean'),\n",
      "            (           'RRate', 'amin'),\n",
      "            (      'Fibrinogen', 'amax'),\n",
      "            (      'Fibrinogen', 'mean'),\n",
      "            (      'Creatinine', 'amin'),\n",
      "            (      'Creatinine', 'amax'),\n",
      "            (      'Creatinine', 'mean'),\n",
      "            (             'AST', 'amin'),\n",
      "            (             'AST', 'amax'),\n",
      "            (             'AST', 'mean'),\n",
      "            (            'FiO2', 'amin'),\n",
      "            (       'Platelets', 'amin'),\n",
      "            (       'Platelets', 'amax'),\n",
      "            (       'Platelets', 'mean'),\n",
      "            (         'Glucose', 'mean'),\n",
      "            (            'ABPd', 'mean'),\n",
      "            (         'Calcium', 'amin'),\n",
      "            (         'Calcium', 'amax'),\n",
      "            (    'Alkalinephos', 'amin'),\n",
      "            (    'Alkalinephos', 'amax'),\n",
      "            (    'Alkalinephos', 'mean'),\n",
      "            (            'SpO2', 'amin'),\n",
      "            ('Bilirubin_direct', 'amin'),\n",
      "            ('Bilirubin_direct', 'amax'),\n",
      "            ('Bilirubin_direct', 'mean'),\n",
      "            (       'Heartrate', 'amax'),\n",
      "            (       'Heartrate', 'mean'),\n",
      "            ( 'Bilirubin_total', 'amin'),\n",
      "            ( 'Bilirubin_total', 'amax'),\n",
      "            ( 'Bilirubin_total', 'mean'),\n",
      "            (       'TroponinI', 'mean'),\n",
      "            (              'pH', 'amin'),\n",
      "            (              'pH', 'amax')],\n",
      "           )\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  14 out of  25 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done  25 out of  25 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.11955657, 0.07269711, 0.0478869 , 0.35077491, 0.134904  ]), 'std_fit_time': array([0.01193395, 0.01162845, 0.00601202, 0.31876596, 0.01772405]), 'mean_score_time': array([0.00303698, 0.00428457, 0.00374098, 0.00277114, 0.00318027]), 'std_score_time': array([0.00012098, 0.00110027, 0.00051542, 0.00080789, 0.00062888]), 'param_alpha': masked_array(data=[0.01, 0.1, 1, 10, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 100}], 'split0_test_score': array([0.62039148, 0.63040864, 0.62641737, 0.66171876, 0.66108772]), 'split1_test_score': array([0.63890781, 0.63177583, 0.62912548, 0.6243949 , 0.6490193 ]), 'split2_test_score': array([0.6328397 , 0.61266386, 0.61157566, 0.61849973, 0.64648791]), 'split3_test_score': array([0.59760248, 0.61252132, 0.61047303, 0.6127566 , 0.63396438]), 'split4_test_score': array([0.650174  , 0.64817816, 0.6360085 , 0.66624946, 0.66540376]), 'mean_test_score': array([0.62798309, 0.62710956, 0.62272001, 0.63672389, 0.65119261]), 'std_test_score': array([0.01797769, 0.01340178, 0.01005455, 0.02260556, 0.01116727]), 'rank_test_score': array([3, 4, 5, 2, 1], dtype=int32), 'split0_train_score': array([0.62179645, 0.6235106 , 0.62221013, 0.64967699, 0.64886208]), 'split1_train_score': array([0.63330656, 0.63194481, 0.63004997, 0.62165669, 0.65268689]), 'split2_train_score': array([0.62770771, 0.62329967, 0.62000007, 0.62646509, 0.65272638]), 'split3_train_score': array([0.60590083, 0.63706458, 0.63522642, 0.64007569, 0.65634638]), 'split4_train_score': array([0.63104255, 0.63040088, 0.62243761, 0.65028604, 0.64969888]), 'mean_train_score': array([0.62395082, 0.62924411, 0.62598484, 0.6376321 , 0.65206412]), 'std_train_score': array([0.00982222, 0.00525359, 0.00573726, 0.0117566 , 0.00264619])}\n",
      "{'alpha': 100}\n",
      "0.6511926128714902\n",
      "ROC AUC for feature LABEL_AST  :  0.6519362765648251\n"
     ]
    }
   ],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "test_pids = list(set(df_test_features.pid))\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import linear_model\n",
    "\n",
    "for i in range(1, 12):\n",
    "   \n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_classif, mode ='k_best', param=40)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(\"For feature \", df_train_labels.columns[i])\n",
    "    print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "\n",
    "    \n",
    "    feature_map_nystroem = Nystroem(kernel = 'rbf',\n",
    "                                 random_state=1,\n",
    "                                 n_components=100)\n",
    "    train_transformed = feature_map_nystroem.fit_transform(train_features)\n",
    "    test_transformed = feature_map_nystroem.transform(test_features)\n",
    "    \n",
    "    clf_w = linear_model.SGDClassifier(max_iter=100000, tol=1e-4,\n",
    "                                     loss = 'epsilon_insensitive', penalty = 'l2')\n",
    "    \n",
    "    parameters = {'alpha':(0.01, 0.1, 1, 10, 100)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 5,\n",
    "                                        refit = True, scoring = 'roc_auc', verbose = 2,\n",
    "                                       n_jobs=6, return_train_score = True)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "    print(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "    # compute probabilites as opposed to predictions\n",
    "    #dual_coefficients = clf.dual_coef_    # do we have to normalize with norm of this vector ?\n",
    "    \n",
    "    distance_hyperplane = clf.decision_function(test_features)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplane[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "    columns_1.append(probability)\n",
    "\n",
    "    \n",
    "    distance_hyperplace_train = clf.decision_function(train_features)\n",
    "    probability = np.empty(len(distance_hyperplace_train))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplace_train[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplace_train[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplace_train[j]))\n",
    "    \n",
    "    tmp = roc_auc_score(y_score= probability, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(     'Lactate', 'amin'),\n",
      "            (        'Temp', 'amin'),\n",
      "            (        'Temp', 'amax'),\n",
      "            (        'HCO3', 'amin'),\n",
      "            (  'BaseExcess', 'amin'),\n",
      "            (       'RRate', 'amin'),\n",
      "            (       'RRate', 'amax'),\n",
      "            (       'RRate', 'mean'),\n",
      "            (  'Fibrinogen', 'amin'),\n",
      "            (  'Fibrinogen', 'amax'),\n",
      "            (  'Fibrinogen', 'mean'),\n",
      "            (       'PaCO2', 'amin'),\n",
      "            (        'FiO2', 'amin'),\n",
      "            (        'FiO2', 'amax'),\n",
      "            (        'FiO2', 'mean'),\n",
      "            (   'Magnesium', 'amin'),\n",
      "            (   'Magnesium', 'mean'),\n",
      "            (     'Calcium', 'amin'),\n",
      "            ('Alkalinephos', 'mean'),\n",
      "            (        'SpO2', 'amin'),\n",
      "            (        'SpO2', 'mean'),\n",
      "            (    'Chloride', 'amin'),\n",
      "            (    'Chloride', 'amax'),\n",
      "            (   'Heartrate', 'amin'),\n",
      "            (   'Heartrate', 'amax'),\n",
      "            (   'Heartrate', 'mean'),\n",
      "            (   'TroponinI', 'amax'),\n",
      "            (   'TroponinI', 'mean'),\n",
      "            (          'pH', 'amin'),\n",
      "            (          'pH', 'amax')],\n",
      "           )\n",
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done  70 out of  70 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.03164723, 0.03072698, 0.05869274, 0.05405605, 0.04510288,\n",
      "       0.0474793 , 0.03472314]), 'std_fit_time': array([0.01118847, 0.01482904, 0.0116606 , 0.01708059, 0.01279342,\n",
      "       0.01319988, 0.00326497]), 'mean_score_time': array([0.0007097 , 0.00060625, 0.00066772, 0.00063264, 0.00067141,\n",
      "       0.00070527, 0.00071063]), 'std_score_time': array([8.76955293e-05, 9.03128067e-05, 7.94591717e-05, 7.54557137e-05,\n",
      "       1.07327584e-04, 9.23153813e-05, 8.62040083e-05]), 'param_alpha': masked_array(data=[0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 100}, {'alpha': 1000}, {'alpha': 10000}], 'split0_test_score': array([-1.53790813e+13, -1.95033267e+09,  3.87315755e-01,  2.06086662e-01,\n",
      "        5.65430994e-02,  3.80195060e-04,  4.60773469e-04]), 'split1_test_score': array([-1.83588860e+13, -1.63048560e+09,  3.36483630e-01,  2.21116292e-01,\n",
      "        1.74819627e-02,  3.31244304e-04, -9.61865187e-04]), 'split2_test_score': array([-6.99058270e+13, -8.00625667e+07,  2.99858979e-01,  1.82180982e-01,\n",
      "        2.18527731e-02,  3.73961330e-03, -2.56646082e-03]), 'split3_test_score': array([-3.25421849e+13, -1.52378911e+07,  3.90682179e-01,  1.89545403e-01,\n",
      "        2.09395034e-02, -2.30315121e-03, -4.19769239e-04]), 'split4_test_score': array([-3.14227886e+13, -2.48261761e+09,  3.66230557e-01,  2.28915476e-01,\n",
      "        2.59054380e-02, -1.57233753e-04, -3.12596692e-03]), 'split5_test_score': array([-2.80916158e+13, -2.13834840e+07,  4.00899324e-01,  2.32116903e-01,\n",
      "        5.06067609e-02,  1.72165787e-03, -3.53776435e-04]), 'split6_test_score': array([-4.69975854e+14, -7.30644812e+07,  3.57749349e-01,  2.07489227e-01,\n",
      "        5.84717239e-02,  1.88679518e-03,  4.35183602e-04]), 'split7_test_score': array([-3.87722741e+13, -2.54224647e+09,  3.29872298e-01,  1.77894250e-01,\n",
      "        3.25713260e-02, -9.22853835e-05, -1.34086228e-03]), 'split8_test_score': array([-2.62876159e+13, -2.03936195e+07,  3.66955544e-01,  1.97460040e-01,\n",
      "        4.93777978e-02,  9.97527741e-04,  3.67193254e-03]), 'split9_test_score': array([ 0.38055189,  0.39475275,  0.3648825 ,  0.2295034 ,  0.01881585,\n",
      "       -0.0061325 , -0.00214614]), 'mean_test_score': array([-7.30736128e+13, -8.81582439e+08,  3.60093011e-01,  2.07230863e-01,\n",
      "        3.52566235e-02,  3.71867149e-05, -6.34694985e-04]), 'std_test_score': array([1.33405403e+14, 1.06440903e+09, 2.92471518e-02, 1.91733204e-02,\n",
      "       1.57880507e-02, 2.54341434e-03, 1.83970567e-03]), 'rank_test_score': array([7, 6, 1, 2, 3, 4, 5], dtype=int32)}\n",
      "{'alpha': 1}\n",
      "0.36009301129154575\n",
      "R2 for feature LABEL_RRate  :  0.33969026083233367\n",
      "MultiIndex([(            'HCO3', 'amin'),\n",
      "            (            'HCO3', 'mean'),\n",
      "            (      'BaseExcess', 'amin'),\n",
      "            (      'BaseExcess', 'amax'),\n",
      "            (           'PaCO2', 'amax'),\n",
      "            (            'SaO2', 'amin'),\n",
      "            (            'SaO2', 'amax'),\n",
      "            (            'SaO2', 'mean'),\n",
      "            (            'ABPm', 'amin'),\n",
      "            (            'ABPm', 'amax'),\n",
      "            (            'ABPm', 'mean'),\n",
      "            (            'ABPd', 'amin'),\n",
      "            (            'ABPd', 'amax'),\n",
      "            (            'ABPd', 'mean'),\n",
      "            (         'Calcium', 'amin'),\n",
      "            ('Bilirubin_direct', 'amin'),\n",
      "            ('Bilirubin_direct', 'amax'),\n",
      "            ('Bilirubin_direct', 'mean'),\n",
      "            (        'Chloride', 'amin'),\n",
      "            (        'Chloride', 'amax'),\n",
      "            (        'Chloride', 'mean'),\n",
      "            (             'Hct', 'amin'),\n",
      "            (       'TroponinI', 'amin'),\n",
      "            (       'TroponinI', 'mean'),\n",
      "            (            'ABPs', 'amin'),\n",
      "            (            'ABPs', 'amax'),\n",
      "            (            'ABPs', 'mean'),\n",
      "            (              'pH', 'amin'),\n",
      "            (              'pH', 'amax'),\n",
      "            (              'pH', 'mean')],\n",
      "           )\n",
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done  70 out of  70 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.1030911 , 0.1020493 , 0.10913539, 0.06844926, 0.06103232,\n",
      "       0.05136783, 0.03195622]), 'std_fit_time': array([0.02177962, 0.02955477, 0.03738074, 0.01775049, 0.02123151,\n",
      "       0.01740126, 0.00352024]), 'mean_score_time': array([0.0008517 , 0.00084929, 0.00074978, 0.00070148, 0.00073855,\n",
      "       0.00071838, 0.00060842]), 'std_score_time': array([1.54247241e-04, 3.40508657e-04, 8.81228611e-05, 8.16952177e-05,\n",
      "       7.62604886e-05, 7.05438192e-05, 9.74766685e-05]), 'param_alpha': masked_array(data=[0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 100}, {'alpha': 1000}, {'alpha': 10000}], 'split0_test_score': array([0.58864045, 0.58286013, 0.55660719, 0.46298718, 0.07109002,\n",
      "       0.0122632 , 0.00217022]), 'split1_test_score': array([ 0.59146645,  0.5779377 ,  0.56991747,  0.4349009 ,  0.10075718,\n",
      "        0.01639822, -0.00533493]), 'split2_test_score': array([ 0.56979402,  0.57074396,  0.54733487,  0.45891729,  0.17482416,\n",
      "        0.00552159, -0.00170014]), 'split3_test_score': array([0.58653413, 0.57755638, 0.56045793, 0.45298105, 0.14780912,\n",
      "       0.00801073, 0.01040564]), 'split4_test_score': array([ 0.60573142,  0.60099401,  0.58291505,  0.42829761,  0.1608579 ,\n",
      "        0.01301154, -0.00918402]), 'split5_test_score': array([0.59817938, 0.59082133, 0.56829321, 0.46557056, 0.09904956,\n",
      "       0.00210264, 0.05403966]), 'split6_test_score': array([ 6.04741615e-01,  5.94926342e-01,  5.62516770e-01,  4.24052389e-01,\n",
      "        1.76732424e-01, -5.58418694e-04,  1.82970228e-05]), 'split7_test_score': array([0.59572492, 0.59239583, 0.57206629, 0.44675561, 0.14739244,\n",
      "       0.0133674 , 0.00446393]), 'split8_test_score': array([0.60024857, 0.59079376, 0.56385038, 0.42394286, 0.13881104,\n",
      "       0.01402687, 0.00396828]), 'split9_test_score': array([0.55217877, 0.54937433, 0.53422715, 0.42811745, 0.09347133,\n",
      "       0.01080667, 0.00445614]), 'mean_test_score': array([0.58932397, 0.58284038, 0.56181863, 0.44265229, 0.13107952,\n",
      "       0.00949504, 0.00633031]), 'std_test_score': array([0.01587347, 0.01418499, 0.01289294, 0.01581211, 0.03528283,\n",
      "       0.0052787 , 0.01674447]), 'rank_test_score': array([1, 2, 3, 4, 5, 6, 7], dtype=int32)}\n",
      "{'alpha': 0.01}\n",
      "0.5893239738517216\n",
      "R2 for feature LABEL_ABPm  :  0.5929486838511817\n",
      "MultiIndex([(             'Age', 'mean'),\n",
      "            (             'Hgb', 'mean'),\n",
      "            (      'BaseExcess', 'amin'),\n",
      "            (      'BaseExcess', 'mean'),\n",
      "            (           'RRate', 'mean'),\n",
      "            (      'Fibrinogen', 'amax'),\n",
      "            (      'Creatinine', 'amin'),\n",
      "            (           'PaCO2', 'amin'),\n",
      "            (           'PaCO2', 'amax'),\n",
      "            (           'PaCO2', 'mean'),\n",
      "            (             'AST', 'amin'),\n",
      "            (             'AST', 'amax'),\n",
      "            (             'AST', 'mean'),\n",
      "            (            'FiO2', 'amin'),\n",
      "            (            'FiO2', 'mean'),\n",
      "            (       'Platelets', 'amax'),\n",
      "            (            'SaO2', 'amin'),\n",
      "            (            'SaO2', 'amax'),\n",
      "            (            'ABPm', 'amax'),\n",
      "            (            'SpO2', 'amin'),\n",
      "            (            'SpO2', 'amax'),\n",
      "            (            'SpO2', 'mean'),\n",
      "            ('Bilirubin_direct', 'amax'),\n",
      "            ('Bilirubin_direct', 'mean'),\n",
      "            (        'Chloride', 'amax'),\n",
      "            (             'Hct', 'amin'),\n",
      "            (             'Hct', 'amax'),\n",
      "            (             'Hct', 'mean'),\n",
      "            (            'ABPs', 'amax'),\n",
      "            (            'ABPs', 'mean')],\n",
      "           )\n",
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done  59 out of  70 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  70 out of  70 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.03350186, 0.03334141, 0.05026207, 0.04324548, 0.05405951,\n",
      "       0.04324682, 0.04234033]), 'std_fit_time': array([0.01678748, 0.01071565, 0.01365156, 0.01457523, 0.01845607,\n",
      "       0.00885837, 0.00784867]), 'mean_score_time': array([0.00068893, 0.00064762, 0.0006433 , 0.00068066, 0.00064712,\n",
      "       0.00076618, 0.00077517]), 'std_score_time': array([1.09856503e-04, 1.01461718e-04, 9.32171399e-05, 8.44263350e-05,\n",
      "       9.60353351e-05, 2.20714554e-04, 1.76662602e-04]), 'param_alpha': masked_array(data=[0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 100}, {'alpha': 1000}, {'alpha': 10000}], 'split0_test_score': array([-2.99789261e+11, -1.59770784e+07,  3.36041704e-01,  1.26520633e-01,\n",
      "        6.31243596e-03,  9.76317922e-04, -1.20749931e-03]), 'split1_test_score': array([-1.55084698e+11, -1.01002308e+07,  3.82546751e-01,  1.66585006e-01,\n",
      "        1.96795962e-02,  3.03210317e-03,  7.28465242e-04]), 'split2_test_score': array([-1.36010008e+11, -9.62684528e+06,  3.99056384e-01,  1.93684628e-01,\n",
      "        1.70772646e-02, -2.87756538e-04, -1.01288191e-03]), 'split3_test_score': array([-1.74880771e+11, -1.22091369e+07,  2.65487247e-01,  1.59759790e-01,\n",
      "        5.00884712e-03,  9.31030740e-04, -8.40303915e-05]), 'split4_test_score': array([-1.09885717e+14, -1.42255026e+07,  3.35528825e-01,  1.73739440e-01,\n",
      "        3.49101257e-02, -7.36761653e-06, -1.84776725e-04]), 'split5_test_score': array([-1.00807257e+11, -1.56214880e+07,  2.84765373e-01,  1.57915486e-01,\n",
      "        8.19322714e-03,  5.26995332e-04, -1.84233720e-03]), 'split6_test_score': array([-1.05708344e+13, -2.74717433e+07,  2.37621388e-01,  1.15658946e-01,\n",
      "        3.78312450e-02, -1.71046319e-03,  3.05319693e-03]), 'split7_test_score': array([-1.21981442e+11, -1.26433062e+07,  2.70708910e-01,  1.45327066e-01,\n",
      "        1.60017155e-02, -1.23406358e-03,  5.50480082e-04]), 'split8_test_score': array([-1.31410388e+11, -5.88110490e+06,  4.99460755e-01,  1.89543585e-01,\n",
      "        3.10140582e-02,  3.28977095e-04, -1.78215867e-03]), 'split9_test_score': array([ 0.25904205,  0.29792203,  0.25192557,  0.20642514, -0.01859172,\n",
      "       -0.00514931, -0.00074164]), 'mean_test_score': array([-1.21576515e+13, -1.23756436e+07,  3.26314291e-01,  1.63515972e-01,\n",
      "        1.57436799e-02, -2.59353309e-04, -2.52318422e-04]), 'std_test_score': array([3.27242017e+13, 6.80432510e+06, 7.78016982e-02, 2.75281321e-02,\n",
      "       1.59557132e-02, 2.04386363e-03, 1.38436168e-03]), 'rank_test_score': array([7, 6, 1, 2, 3, 5, 4], dtype=int32)}\n",
      "{'alpha': 1}\n",
      "0.32631429102813614\n",
      "R2 for feature LABEL_SpO2  :  0.34495010467434395\n",
      "MultiIndex([(             'Age', 'mean'),\n",
      "            (         'Lactate', 'amin'),\n",
      "            (         'Lactate', 'amax'),\n",
      "            (         'Lactate', 'mean'),\n",
      "            (            'Temp', 'amax'),\n",
      "            (            'Temp', 'mean'),\n",
      "            (            'HCO3', 'amin'),\n",
      "            (            'HCO3', 'amax'),\n",
      "            (      'BaseExcess', 'amax'),\n",
      "            (      'Fibrinogen', 'mean'),\n",
      "            (             'WBC', 'amin'),\n",
      "            (             'WBC', 'amax'),\n",
      "            (           'PaCO2', 'amax'),\n",
      "            (             'AST', 'amax'),\n",
      "            (            'FiO2', 'amin'),\n",
      "            (         'Calcium', 'amin'),\n",
      "            (         'Calcium', 'amax'),\n",
      "            (         'Calcium', 'mean'),\n",
      "            ('Bilirubin_direct', 'amin'),\n",
      "            ('Bilirubin_direct', 'amax'),\n",
      "            ('Bilirubin_direct', 'mean'),\n",
      "            (       'Heartrate', 'amin'),\n",
      "            (       'Heartrate', 'amax'),\n",
      "            (       'Heartrate', 'mean'),\n",
      "            (       'TroponinI', 'amin'),\n",
      "            (       'TroponinI', 'amax'),\n",
      "            (       'TroponinI', 'mean'),\n",
      "            (              'pH', 'amin'),\n",
      "            (              'pH', 'amax'),\n",
      "            (              'pH', 'mean')],\n",
      "           )\n",
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done  59 out of  70 | elapsed:    0.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done  70 out of  70 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.10075295, 0.07536445, 0.08998957, 0.05955398, 0.04288311,\n",
      "       0.04519734, 0.03126996]), 'std_fit_time': array([0.02017355, 0.01893636, 0.03052114, 0.01748754, 0.00618942,\n",
      "       0.01140093, 0.00336305]), 'mean_score_time': array([0.00097251, 0.00076177, 0.00089819, 0.00095522, 0.0006634 ,\n",
      "       0.00062163, 0.00059776]), 'std_score_time': array([3.21707157e-04, 2.95204074e-04, 1.99000950e-04, 6.13631049e-04,\n",
      "       7.33118522e-05, 6.97374996e-05, 1.08064115e-04]), 'param_alpha': masked_array(data=[0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 10}, {'alpha': 100}, {'alpha': 1000}, {'alpha': 10000}], 'split0_test_score': array([0.6255956 , 0.61474629, 0.59188106, 0.39540125, 0.06063833,\n",
      "       0.00776192, 0.02893701]), 'split1_test_score': array([0.61630002, 0.60649943, 0.58182793, 0.34252497, 0.0546376 ,\n",
      "       0.00091526, 0.00146165]), 'split2_test_score': array([0.62321718, 0.62036284, 0.60785263, 0.35562566, 0.07296809,\n",
      "       0.00381998, 0.00079676]), 'split3_test_score': array([ 0.59179884,  0.61905805,  0.60356938,  0.37782062,  0.06481517,\n",
      "        0.00742349, -0.00190582]), 'split4_test_score': array([ 6.32810022e-01,  6.29444857e-01,  6.09028727e-01,  3.50677340e-01,\n",
      "        9.45439632e-02,  6.80177125e-03, -1.95914961e-04]), 'split5_test_score': array([ 0.5956629 ,  0.60050745,  0.58347231,  0.37692266,  0.1165508 ,\n",
      "       -0.00149211, -0.00098475]), 'split6_test_score': array([ 6.44127926e-01,  6.28685106e-01,  6.16261682e-01,  4.57235835e-01,\n",
      "        9.59400574e-02, -2.94663433e-04,  4.83961111e-04]), 'split7_test_score': array([ 0.59570181,  0.59377605,  0.57245129,  0.38780126,  0.09809521,\n",
      "       -0.00390784,  0.0020178 ]), 'split8_test_score': array([ 4.92841357e-01,  5.77546887e-01,  5.55001840e-01,  3.89915696e-01,\n",
      "        7.83169879e-02,  5.42240268e-03, -2.52407237e-04]), 'split9_test_score': array([0.61672441, 0.61378106, 0.57769001, 0.39164418, 0.09645671,\n",
      "       0.02492479, 0.00154927]), 'mean_test_score': array([0.60347801, 0.6104408 , 0.58990369, 0.38255695, 0.08329629,\n",
      "       0.0051375 , 0.00319076]), 'std_test_score': array([0.04028634, 0.0153959 , 0.01830797, 0.03050325, 0.018953  ,\n",
      "       0.00762458, 0.00865865]), 'rank_test_score': array([2, 1, 3, 4, 5, 6, 7], dtype=int32)}\n",
      "{'alpha': 0.1}\n",
      "0.6104408029302062\n",
      "R2 for feature LABEL_Heartrate  :  0.6133354924521283\n"
     ]
    }
   ],
   "source": [
    "# labels that have a real value\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "    # feature selection\n",
    "    transformer =  GenericUnivariateSelect(score_func= mutual_info_regression, mode ='k_best', param = 30)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(df_train_agg_features.columns[transformer.get_support(indices = True)])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    feature_map_nystroem = Nystroem(kernel = 'rbf', degree = 5,\n",
    "                                 random_state=1,\n",
    "                                 n_components=100)\n",
    "    train_transformed = feature_map_nystroem.fit_transform(train_features)\n",
    "    test_transformed = feature_map_nystroem.transform(test_features)\n",
    "    \n",
    "    clf_w = linear_model.SGDRegressor(max_iter=100000, tol=1e-4,\n",
    "                                     loss = 'epsilon_insensitive', penalty = 'l2',\n",
    "                                     validation_fraction = 0.2, l1_ratio= 0.3)\n",
    "# #     clf_w = NuSVR(nu=0.5, kernel = 'linear')\n",
    "    parameters = {'alpha':(0.01, 0.1, 1,10, 100, 1000, 10000)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 10,\n",
    "                                       refit = True, scoring = 'r2', verbose = 2, n_jobs=6)\n",
    "#     clf = KernelRidge(kernel = 'poly', degree = 5)\n",
    "#     parameters = {'alpha':(0.1,1,10,30)}\n",
    "#     clf = model_selection.GridSearchCV(estimator= clf, param_grid = parameters, cv = 3,\n",
    "#                                       refit = True, scoring = 'r2', verbose = 2, n_jobs=6)\n",
    "    clf.fit(train_features, df_train_labels.iloc[:,i])\n",
    "    \n",
    "    print(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "\n",
    "    pred_train = clf.predict(train_features)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    \n",
    "    pred = clf.predict(test_features)\n",
    "    columns_2.append(pred)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 12664)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(columns_final))\n",
    "result = pd.DataFrame(columns_final).transpose()\n",
    "result.columns = list(df_train_labels)\n",
    "result.to_csv('./Results/prediction.csv.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./Results/prediction.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
