{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ahmadrezauf/IML_Projects/blob/master/task_2/ns_reboot_task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcjdWJ7OUoXR"
   },
   "source": [
    "# Support vector machines for medical predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80PaTcfHVUCr"
   },
   "source": [
    "#### Set up directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cBkOnoh0pLVo",
    "outputId": "1895635d-6691-4bb7-af63-49c2b7057e26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/IML/IML_Projects/task_2'"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount= True)\n",
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/IML/IML_Projects/task_2\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L4i-_fs24jYr",
    "outputId": "6195d769-f614-4095-ca3c-e4143a7c470d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/IML/IML_Projects/task_2'"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQxnwMkzU3QW"
   },
   "source": [
    "#### load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRZU5clAUoXR"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectPercentile, GenericUnivariateSelect, chi2, mutual_info_classif, mutual_info_regression, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxAmfO6vU7LF"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yelxz59KUoXW"
   },
   "outputs": [],
   "source": [
    "# load data from csv file\n",
    "df_train_features = pd.read_csv ('train_features.csv')\n",
    "df_train_labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "# Load test data\n",
    "df_test_features = pd.read_csv ('test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEDVtlgQPQmh"
   },
   "outputs": [],
   "source": [
    "# Sort labels\n",
    "df_train_labels = df_train_labels.sort_values('pid')\n",
    "df_train_features = df_train_features.sort_values(['pid','Time'])\n",
    "df_test_features = df_test_features.sort_values('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlTJVYVgQMLj"
   },
   "outputs": [],
   "source": [
    "# extract pid\n",
    "train_pids = df_train_features['pid'].unique()\n",
    "test_pids = df_test_features['pid'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UrYHe8wqUoXo"
   },
   "source": [
    "### Train data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYbrwnAHUoXp"
   },
   "outputs": [],
   "source": [
    "# Do we want to keep the time as a feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXE9kAS6UoXr"
   },
   "outputs": [],
   "source": [
    "# Patient by patient pre-processing for imputation and feature generation\n",
    "# df_train_patient = df_train_features.groupby(['pid'], as_index=False).apply(lambda group: group.ffill())\n",
    "# df_train_patient = df_train_patient.groupby(['pid'], as_index=False).apply(lambda group: group.bfill())\n",
    "\n",
    "# can also use data.interpolate to do a linear interpolation of the missing values\n",
    "df_train_patient = df_train_features.groupby(['pid'], as_index=False).apply(lambda group: group.interpolate(method = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "UmJNo9w_ON0J",
    "outputId": "a27f2983-292e-4a66-9e8e-edf7bb3b4d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    RRate  Fibrinogen  Phosphate  ...  TroponinI   ABPs        pH\n",
      "0    16.0         NaN        NaN  ...        NaN  142.0  7.330000\n",
      "5    16.0         NaN        NaN  ...        NaN  106.0  7.330000\n",
      "1    16.0         NaN        NaN  ...        NaN  125.0  7.330000\n",
      "2    18.0         NaN        NaN  ...        NaN  110.0  7.370000\n",
      "4    18.0         NaN        NaN  ...        NaN  100.0  7.410000\n",
      "11   18.0         NaN        NaN  ...        NaN  102.0  7.390000\n",
      "3    18.0         NaN        NaN  ...        NaN  104.0  7.370000\n",
      "7    18.0         NaN        NaN  ...        NaN  121.0  7.376667\n",
      "8    12.0         NaN        4.6  ...        NaN  118.0  7.383333\n",
      "9    18.0         NaN        4.6  ...        NaN  110.0  7.390000\n",
      "10   18.0         NaN        4.6  ...        NaN  124.0  7.390000\n",
      "6    18.0         NaN        4.6  ...        NaN  112.0  7.390000\n",
      "\n",
      "[12 rows x 26 columns]\n",
      "    RRate  Fibrinogen  Phosphate  WBC  ...  Bilirubin_total  TroponinI   ABPs    pH\n",
      "0    16.0         NaN        NaN  6.3  ...              NaN        NaN  142.0  7.33\n",
      "5    16.0         NaN        NaN  NaN  ...              NaN        NaN  106.0   NaN\n",
      "1    16.0         NaN        NaN  NaN  ...              NaN        NaN  125.0  7.33\n",
      "2    18.0         NaN        NaN  NaN  ...              NaN        NaN  110.0  7.37\n",
      "4    18.0         NaN        NaN  NaN  ...              NaN        NaN  100.0  7.41\n",
      "11   18.0         NaN        NaN  NaN  ...              NaN        NaN  102.0   NaN\n",
      "3    18.0         NaN        NaN  NaN  ...              NaN        NaN  104.0  7.37\n",
      "7    18.0         NaN        NaN  NaN  ...              NaN        NaN  121.0   NaN\n",
      "8    12.0         NaN        4.6  4.7  ...              NaN        NaN  118.0   NaN\n",
      "9    18.0         NaN        NaN  4.7  ...              NaN        NaN  110.0  7.39\n",
      "10   18.0         NaN        NaN  NaN  ...              NaN        NaN  124.0  7.39\n",
      "6    18.0         NaN        NaN  NaN  ...              NaN        NaN  112.0   NaN\n",
      "\n",
      "[12 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train_patient.iloc[0:12,10:])\n",
    "print(df_train_features.iloc[0:12,10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JLnLyxBUoXu"
   },
   "outputs": [],
   "source": [
    "# compute the features for each patient (pid)\n",
    "df_train_agg_features = df_train_patient.groupby('pid').agg([np.nanmean, 'last', 'first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "9hOsN-3P8KzR",
    "outputId": "0649dca7-af0c-4d9d-d585-5cf284de4723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       Time              Age        ...   ABPs               pH            \n",
      "      mean last first  mean  last  ...   last  first      mean  last first\n",
      "pid                                ...                                    \n",
      "1      8.5   14     3  34.0  34.0  ...  102.0  142.0  7.381667  7.39  7.33\n",
      "2      6.5   12     1  86.0  86.0  ...  136.0  148.0       NaN   NaN   NaN\n",
      "4      6.5   12     1  66.0  66.0  ...   96.0  146.0       NaN   NaN   NaN\n",
      "6      7.5   13     2  66.0  66.0  ...   98.0   97.0  7.348182  7.34  7.35\n",
      "8      6.5   12     1  42.0  42.0  ...  204.0  220.0       NaN   NaN   NaN\n",
      "...    ...  ...   ...   ...   ...  ...    ...    ...       ...   ...   ...\n",
      "31653  6.5   12     1  52.0  52.0  ...   88.0   96.0  7.330000  7.33  7.33\n",
      "31654  6.5   12     1  66.0  66.0  ...  153.0  166.0       NaN   NaN   NaN\n",
      "31656  6.5   12     1  44.0  44.0  ...  104.0  114.0  7.311818  7.33  7.25\n",
      "31657  6.5   12     1  70.0  70.0  ...  106.0  124.0       NaN   NaN   NaN\n",
      "31658  6.5   12     1  60.0  60.0  ...  135.0  137.0       NaN   NaN   NaN\n",
      "\n",
      "[18995 rows x 108 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_train_agg_features.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0nrPJXcUoXx"
   },
   "outputs": [],
   "source": [
    "# scale the data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "# standard_scalar = preprocessing.StandardScaler()\n",
    "data_imputed = min_max_scaler.fit_transform(df_train_agg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "5CovPbADUoX0",
    "outputId": "b2c9adbb-4a0d-4651-b610-5e40e9d69b64"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-f6f2922cb90c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_imputed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             reduce_func=process_chunk)\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;31m# process_chunk modifies X in place. No return value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0;32m-> 1595\u001b[0;31m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[1;32m   1596\u001b[0m         if ((X is Y or Y is None)\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mnan_euclidean_distances\u001b[0;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mpresent_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmissing_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mpresent_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_X\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mmissing_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mpresent_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresent_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpresent_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# avoid divide by zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# impute missing data points\n",
    "#imp = SimpleImputer(strategy=\"mean\")\n",
    "imputer = KNNImputer()\n",
    "data_train_scaled = imputer.fit_transform(data_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5YBr1JVaDrFL",
    "outputId": "050faec8-6be3-42eb-fbc7-20767066d5e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# use a different method to impute the data: Bayseian Ridge\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imp_mean = IterativeImputer(random_state=0, skip_complete = True)\n",
    "imp_mean.fit(data_imputed)\n",
    "data_train_scaled = imp_mean.transform(data_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWUuNp_dUoX3"
   },
   "outputs": [],
   "source": [
    "# REARRANGE THE LABELS, TO MATCH THE REARRANGED FEATURES\n",
    "df_train_labels_sorted = df_train_labels.sort_values(by = 'pid')\n",
    "# print(df_train_labels_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wA-IjjmvUoYC"
   },
   "source": [
    "### Test Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjOpnkssUoYF"
   },
   "outputs": [],
   "source": [
    "# Patient by patient pre-processing for imputation and feature generation\n",
    "# df_test_patient = df_test_features.groupby(['pid'], as_index=False).apply(lambda group: group.ffill())\n",
    "# df_test_patient = df_test_patient.groupby(['pid'], as_index=False).apply(lambda group: group.bfill())\n",
    "\n",
    "# can also use data.interpolate to do a linear interpolation of the missing values\n",
    "df_test_patient = df_test_features.groupby(['pid'], as_index=False).apply(lambda group: group.interpolate(method = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFeXOnDQUoYH"
   },
   "outputs": [],
   "source": [
    "# compute the features for each patient (pid)\n",
    "df_test_agg_features = df_test_patient.groupby('pid').agg([np.min, np.max, np.mean, np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPexanKfUoYJ"
   },
   "outputs": [],
   "source": [
    "# scale the data\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "# standard_scalar = preprocessing.StandardScaler()\n",
    "data_test_imputed = min_max_scaler.fit_transform(df_test_agg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-8Q9FaQUoYM"
   },
   "outputs": [],
   "source": [
    "# impute missing data points\n",
    "# should this be a newly fitted imputation or the same one from the train data?\n",
    "#imp = SimpleImputer(strategy=\"mean\")\n",
    "imputer = KNNImputer()\n",
    "data_test_scaled = imputer.fit_transform(data_test_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ov_rU1OUoYO"
   },
   "source": [
    "## Fit a model & Predict test features\n",
    "* label 1: 0.78\n",
    "\n",
    "use 2 features\n",
    "\n",
    "transformer = GenericUnivariateSelect(score_func= mutual_info_classif, mode = 'k_best', param=2)\n",
    "\n",
    "rbf kernel with auto gamma\n",
    "\n",
    "clf_w = SVC(kernel = 'rbf', gamma = 'scale', class_weight = 'balanced', verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXXnq4smbpV9"
   },
   "source": [
    "Start with the first feature to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_h1gbtwYJEy"
   },
   "outputs": [],
   "source": [
    "# Create folds for CV on number of features\n",
    "kfold_splits = 5\n",
    "folds = list(StratifiedKFold(n_splits=kfold_splits, shuffle=True, random_state=10).split(data_train_scaled, df_train_labels_sorted.iloc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "colab_type": "code",
    "id": "kJ-JOuuoYc4y",
    "outputId": "05827667-ad94-417b-ac57-9c0c18fe5a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Training on fold 1/5...\n",
      "ROC AUC for test feature :  0.6204365927586301 for the train feature: 0.9613838100707284\n",
      "Training on fold 2/5...\n",
      "ROC AUC for test feature :  0.6768591664396623 for the train feature: 0.967742327271191\n",
      "Training on fold 3/5...\n",
      "ROC AUC for test feature :  0.6820131343709457 for the train feature: 0.9674559272088094\n",
      "Training on fold 4/5...\n",
      "ROC AUC for test feature :  0.6498952660242984 for the train feature: 0.9736277170928237\n",
      "Training on fold 5/5...\n",
      "ROC AUC for test feature :  0.6320061468070111 for the train feature: 0.9659822666595086\n",
      "10\n",
      "Training on fold 1/5...\n",
      "ROC AUC for test feature :  0.8606335199954749 for the train feature: 0.958073279574925\n",
      "Training on fold 2/5...\n",
      "ROC AUC for test feature :  0.8421679684868193 for the train feature: 0.966542070399806\n",
      "Training on fold 3/5...\n",
      "ROC AUC for test feature :  0.8838478946759831 for the train feature: 0.9610111280166143\n",
      "Training on fold 4/5...\n",
      "ROC AUC for test feature :  0.8300422735559875 for the train feature: 0.9729667329022944\n",
      "Training on fold 5/5...\n",
      "ROC AUC for test feature :  0.8130467987200681 for the train feature: 0.9655164344074775\n",
      "11\n",
      "Training on fold 1/5...\n",
      "ROC AUC for test feature :  0.6237433005664355 for the train feature: 0.9244878707413153\n",
      "Training on fold 2/5...\n",
      "ROC AUC for test feature :  0.6214897667777248 for the train feature: 0.9008167109159274\n",
      "Training on fold 3/5...\n",
      "ROC AUC for test feature :  0.6541712247872948 for the train feature: 0.9098989699621779\n",
      "Training on fold 4/5...\n",
      "ROC AUC for test feature :  0.6296545459121914 for the train feature: 0.9212467611468015\n",
      "Training on fold 5/5...\n",
      "ROC AUC for test feature :  0.6448276945555094 for the train feature: 0.9213408481051801\n"
     ]
    }
   ],
   "source": [
    "for label in range(9,12):\n",
    "\n",
    "# go through \n",
    "  print(label)\n",
    "  for index, (train_indices, val_indices) in enumerate(folds):\n",
    "    print(\"Training on fold \" + str(index+1) + \"/5...\")\n",
    "    # divide data into train and validation set\n",
    "    xtrain, xval = data_train_scaled[train_indices], data_train_scaled[val_indices]\n",
    "    ytrain, yval = df_train_labels_sorted.iloc[train_indices, label], df_train_labels_sorted.iloc[val_indices, label]\n",
    "\n",
    "    transformer = GenericUnivariateSelect(score_func= f_classif, mode = 'fpr', param= 0.01)\n",
    "    train_features = transformer.fit_transform(xtrain, ytrain)\n",
    "    test_features = transformer.transform(xval)\n",
    "\n",
    "    #print(df_train_agg_features.columns[transformer.get_support(indices = True)], end = ' ')\n",
    "\n",
    "    clf = SVC(kernel = 'rbf', gamma = 'scale', class_weight = 'balanced', verbose = 0)\n",
    "  \n",
    "    parameters = {'C':(0.1, 1, 10)}\n",
    "    #clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 3, refit = True, scoring = 'roc_auc', verbose = 0, n_jobs=20, return_train_score = True)\n",
    "  \n",
    "    clf.fit(train_features, ytrain)\n",
    "\n",
    "  # compute probabilites as opposed to predictions for test feature\n",
    "    distance_hyperplane = clf.decision_function(test_features)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "      if distance_hyperplane[j] < 0:\n",
    "          probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "      else:\n",
    "          probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "  \n",
    "    temp = roc_auc_score(y_score= probability, y_true= yval)\n",
    "\n",
    "  # compute probabilites as opposed to predictions for test feature\n",
    "    distance_hyperplane = clf.decision_function(train_features)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "      if distance_hyperplane[j] < 0:\n",
    "          probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "      else:\n",
    "          probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "  \n",
    "    temp_train = roc_auc_score(y_score= probability, y_true= ytrain)\n",
    "\n",
    "    print(\"ROC AUC for test feature : \", temp, \"for the train feature:\", temp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "colab_type": "code",
    "id": "kTpMO9LPWReH",
    "outputId": "d99d650b-c21e-4443-bfc1-85bb89481c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Training on fold 1/5...\n",
      "R2 for feature :  0.40084199970215173 test R2:  0.4760262246230115\n",
      "Training on fold 2/5...\n",
      "R2 for feature :  0.40898633297419473 test R2:  0.46706767253269543\n",
      "Training on fold 3/5...\n",
      "R2 for feature :  0.391802336558151 test R2:  0.47623432684042644\n",
      "Training on fold 4/5...\n",
      "R2 for feature :  0.3719633355888945 test R2:  0.47318981045308195\n",
      "Training on fold 5/5...\n",
      "R2 for feature :  0.39934525642789087 test R2:  0.47498491011554667\n",
      "13\n",
      "Training on fold 1/5...\n",
      "R2 for feature :  0.5908822297373095 test R2:  0.6086536145913657\n",
      "Training on fold 2/5...\n",
      "R2 for feature :  0.579568140019117 test R2:  0.6137590982361404\n",
      "Training on fold 3/5...\n",
      "R2 for feature :  0.6099388497567091 test R2:  0.6045641834988276\n",
      "Training on fold 4/5...\n",
      "R2 for feature :  0.5752596995424447 test R2:  0.6117113100239294\n",
      "Training on fold 5/5...\n",
      "R2 for feature :  0.6013797906959275 test R2:  0.6108884923148217\n",
      "14\n",
      "Training on fold 1/5...\n",
      "R2 for feature :  0.3680057324458931 test R2:  0.38739365139169124\n",
      "Training on fold 2/5...\n",
      "R2 for feature :  0.30951615816309674 test R2:  0.40075061124519784\n",
      "Training on fold 3/5...\n",
      "R2 for feature :  0.27537620393216666 test R2:  0.408128461852884\n",
      "Training on fold 4/5...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-160d3a1b102e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mpred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpred_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mpred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mtemp_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R2 for feature : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test R2: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for label in range(12, 16):\n",
    "\n",
    "  best_score = 0\n",
    "  best_transformer = None\n",
    "  best_model = None\n",
    "\n",
    "  print(label)\n",
    "  for index, (train_indices, val_indices) in enumerate(folds):\n",
    "    print(\"Training on fold \" + str(index+1) + \"/5...\")\n",
    "\n",
    "    # divide data into train and validation set\n",
    "    xtrain, xval = data_train_scaled[train_indices], data_train_scaled[val_indices]\n",
    "    ytrain, yval = df_train_labels_sorted.iloc[train_indices, label], df_train_labels_sorted.iloc[val_indices, label]\n",
    "\n",
    "    # transformer = GenericUnivariateSelect(score_func= mutual_info_regression, mode = 'k_best', param=10)\n",
    "    # transformer = GenericUnivariateSelect(score_func= mutual_info_regression, mode = 'fpr', param=0.05)\n",
    "    transformer = GenericUnivariateSelect(score_func= f_classif, mode = 'fdr', param= 0.05)\n",
    "    train_features = transformer.fit_transform(xtrain, ytrain)\n",
    "    test_features = transformer.transform(xval)\n",
    "    \n",
    "    #print(df_train_agg_features.columns[transformer.get_support(indices = True)], end = ' ')\n",
    "    \n",
    "    # fit model\n",
    "    clf = SVR(verbose = False)\n",
    "    clf.fit(train_features, ytrain)\n",
    "   \n",
    "    pred_val = clf.predict(test_features)\n",
    "    tmp = r2_score(y_pred= pred_val, y_true=yval)\n",
    "    pred_train = clf.predict(train_features)\n",
    "    temp_train = r2_score(y_pred= pred_train, y_true=ytrain)\n",
    "    print(\"R2 for feature : \", tmp, \"test R2: \", temp_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8blbmPIWRtp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPlrq9jlwNNb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mr7IlMgxwNRY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L02Gy3z0wNVj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9QObyuWwNcc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeZhIFYUwNj3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBOBhFSWwObT"
   },
   "source": [
    "#### Archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niM4x4JgwNZd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxZjpq7bUoYP"
   },
   "outputs": [],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "test_pids = list(set(df_test_features.pid))\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "for i in range(1, 12):\n",
    "    # feature selection\n",
    "    transformer = GenericUnivariateSelect(score_func= f_classif, mode = 'fpr', param= 0.01)\n",
    "    # transformer = SelectPercentile( mutual_info_classif)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels_sorted.iloc[:,i])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    clf = SVC(C = 0.1, class_weight = 'balanced', verbose = True)\n",
    "    clf.fit(train_features, df_train_labels_sorted.iloc[:,i])\n",
    "    # pred = clf.predict(df_test_agg_imputed_features)\n",
    "    # columns_1.append(pred)\n",
    "     \n",
    "    # compute probabilites as opposed to predictions\n",
    "    dual_coefficients = clf.dual_coef_    # do we have to normalize with norm of this vector ?\n",
    "    distance_hyperplane = clf.decision_function(test_features)\n",
    "    probability = np.empty(len(distance_hyperplane))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplane[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplane[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplane[j]))\n",
    "    columns_1.append(probability)\n",
    "\n",
    "\n",
    "    \n",
    "    distance_hyperplace_train = clf.decision_function(train_features)\n",
    "    probability = np.empty(len(distance_hyperplace_train))\n",
    "    for j in range(0, len(probability)):\n",
    "        if distance_hyperplace_train[j] < 0:\n",
    "            probability[j] = 1 - 1/(1 + math.exp(distance_hyperplace_train[j]))\n",
    "        else:\n",
    "            probability[j] = 1/(1 + math.exp(-distance_hyperplace_train[j]))\n",
    "      \n",
    "    tmp = roc_auc_score(y_score= probability, y_true= df_train_labels_sorted.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bASjTWKGUoYS"
   },
   "outputs": [],
   "source": [
    "# labels that have a real value\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "    \n",
    "    # feature selection\n",
    "    transformer = GenericUnivariateSelect(score_func= mutual_info_regression, mode = 'k_best', param=15)\n",
    "    train_features = transformer.fit_transform(data_train_scaled, df_train_labels_sorted.iloc[:,i])\n",
    "    test_features = transformer.transform(data_test_scaled)\n",
    "    \n",
    "    # fit model\n",
    "    clf = SVR(verbose = True)\n",
    "    clf.fit(train_features, df_train_labels_sorted.iloc[:,i])\n",
    "   \n",
    "    pred_train = clf.predict(train_features)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels_sorted.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)\n",
    "    \n",
    "    pred = clf.predict(test_features)\n",
    "    columns_2.append(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBtiwp04UoYV"
   },
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHvueyxIUoYY"
   },
   "source": [
    "### predict with Support vector regression and then compute sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUuM6IR1UoYY",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# first for the labels that have an output [0,1]\n",
    "\n",
    "columns_1 = [test_pids]\n",
    "\n",
    "for i in range(1,12):\n",
    "    \n",
    "    clf = SVR(kernel = 'poly', degree = 3, max_iter = 10000)\n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    pred = clf.predict(data_test_scaled)\n",
    "    prob = np.empty(len(pred))\n",
    "    for j in range(0, len(pred)):\n",
    "        prob[j] = 1 / (1 + math.exp(-pred[j]))\n",
    "    columns_1.append(prob)\n",
    "    \n",
    "    pred_train = clf.predict(data_train_scaled)\n",
    "    prob_train = np.empty(len(pred_train))\n",
    "    for j in range(0, len(pred_train)):\n",
    "        prob_train[j] = 1 / (1 + math.exp(-pred_train[j]))    \n",
    "    tmp = roc_auc_score(y_score= prob_train, y_true= df_train_labels.iloc[:,i])\n",
    "    print(\"ROC AUC for feature\", list(df_train_labels)[i] , \" : \", tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytxIIl90UoYa",
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# labels that have a real value\n",
    "\n",
    "columns_2 = []\n",
    "\n",
    "for i in range(12, 16):\n",
    "    clf_w = LinearSVR()\n",
    "    parameters = {'C':np.linspace(0.1,10, 20)}\n",
    "    clf = model_selection.GridSearchCV(estimator= clf_w, param_grid = parameters, cv = 5,\n",
    "                                       refit = True, scoring = 'r2', verbose = 1, n_jobs=6)\n",
    "    \n",
    "    clf.fit(data_train_scaled, df_train_labels.iloc[:,i])\n",
    "    print(clf.cv_results_)\n",
    "    pred = clf.predict(data_test_scaled)\n",
    "    columns_2.append(pred)\n",
    "    \n",
    "    pred_train = clf.predict(data_train_scaled)\n",
    "    tmp = r2_score(y_pred= pred_train, y_true=df_train_labels.iloc[:,i])\n",
    "    print(\"R2 for feature\", list(df_train_labels)[i] , \" : \", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qgueqChgUoYc"
   },
   "outputs": [],
   "source": [
    "columns_final = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmI6GAeRUoYe"
   },
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IW0rzs47UoYf"
   },
   "outputs": [],
   "source": [
    "print(np.shape(columns_final))\n",
    "result = pd.DataFrame(columns_final).transpose()\n",
    "result.columns = list(df_train_labels)\n",
    "result.to_csv('./Results/prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Phn5xHYUoYh"
   },
   "outputs": [],
   "source": [
    "result.to_csv('./Results/prediction.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8AifyVAUoYk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "ns_reboot_task2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
