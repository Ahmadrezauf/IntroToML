{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IML_Task 3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0ZvOZjQhVaf",
        "colab_type": "text"
      },
      "source": [
        "Testing google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLodKHnmhaFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pickle\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.util import deprecation\n",
        "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7shaT-b1x4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!if [ ! -f Archive.zip ]; then wget -nv https://drive.google.com/open?id=1g7aT8cMkFAFlk6wxkiEH3mgFVp2Xa1l9 -O Archive.zip; fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4i-_fs24jYr",
        "colab_type": "code",
        "outputId": "13fec709-fe84-49dc-e2cc-072f54ab79c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQXuKcg4h71k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat_train = pd.read_csv(\"./Data/train.csv\")\n",
        "dat_test = pd.read_csv(\"./Data/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QH_sN8RiI_n",
        "colab_type": "code",
        "outputId": "89f0feaa-09eb-4e12-c32b-715b53145ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def split_convert(word_inp): \n",
        "    return [ord(i) for i in word_inp] \n",
        "print(split_convert(\"hello\"))\n",
        "#tf.one_hot([1,2,3,4,5,1,2,4],  depth = 4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[104, 101, 108, 108, 111]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oiAKv-SoLs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seqs = [split_convert(i) for i in dat_train.iloc[:,0]]\n",
        "train_labels = [i for i in dat_train.iloc[:,1]]\n",
        "test_seqs = [split_convert(i) for i in dat_test.iloc[:,0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDJA5RrP1FgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "# taken from: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "\n",
        "def get_recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def get_precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def get_f1(y_true, y_pred):\n",
        "    precision = get_precision(y_true, y_pred)\n",
        "    recall = get_recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUwlmVhLW07X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weight = {0:1, 1:12}\n",
        "NEPOCHS = 60    \n",
        "BATCHSIZE = 64\n",
        "VALIDATIONSPLIT = 0.2\n",
        "HIDDENSIZE = 80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLkZ2kHyfqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import Callback,ModelCheckpoint\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = 80, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dense(HIDDENSIZE, input_dim = HIDDENSIZE, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(2, input_dim = HIDDENSIZE, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "  model.compile(optimizer='rmsprop',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=[get_f1, get_recall])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmVPZ0er052Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "kfold_splits = 5\n",
        "folds = list(StratifiedKFold(n_splits=kfold_splits, shuffle=True, random_state=1).split(train_seqs, train_labels))\n",
        "\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "train_seqs_onehot = onehot_encoder.fit_transform(train_seqs)\n",
        "test_seqs_onehot = onehot_encoder.transform(test_seqs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd7SibE9ktB0",
        "colab_type": "code",
        "outputId": "7a594404-5745-41ae-d7dc-ec5168dbe885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "train_labels_onehot = keras.utils.to_categorical(train_labels, num_classes=2)\n",
        "\n",
        "mode_path = './models/mlp_v2.h5'\n",
        "\n",
        "model = None\n",
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "best_fold = -1\n",
        "best_score = 0\n",
        "best_model = None\n",
        "\n",
        "for index, (train_indices, val_indices) in enumerate(folds):\n",
        "  print(\"Training on fold \" + str(index+1) + \"/5...\")\n",
        "  # Generate batches from indices\n",
        "  xtrain, xval = train_seqs_onehot[train_indices], train_seqs_onehot[val_indices]\n",
        "  ytrain, yval = train_labels_onehot[train_indices], train_labels_onehot[val_indices]\n",
        "\n",
        "  # xtrain_onehot = onehot_encoder.transform(xtrain)\n",
        "  # xval_onehot = onehot_encoder.transform(xval)\n",
        "  # ytrain_onehot = keras.utils.to_categorical(y_train, num_classes=2)\n",
        "  # yval_onehot = keras.utils.to_categorical(y_val, num_classes=2)\n",
        "\n",
        "  model = None\n",
        "  model = create_model()\n",
        "\n",
        "  # model.summary()\n",
        "  callbacks = [ModelCheckpoint(filepath=mode_path, save_best_only=True)]\n",
        "  model.fit(xtrain, ytrain, validation_data = (xval, yval), epochs = NEPOCHS, batch_size=BATCHSIZE, verbose = 1 ,\n",
        "            callbacks=callbacks, class_weight = class_weight)  # starts training\n",
        "\n",
        "  # get the best fold based on the best f1 score\n",
        "  y_pred = model.predict(xval, batch_size=BATCHSIZE, verbose=1)\n",
        "  y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "  tmp_score = metrics.f1_score(np.argmax(yval, axis=1),y_pred_bool)\n",
        "  print(\"F1 score for this fold is : \", tmp_score)\n",
        "  if(tmp_score > best_score):\n",
        "    best_fold = index\n",
        "    best_model = model\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 162       \n",
            "=================================================================\n",
            "Total params: 78,882\n",
            "Trainable params: 78,402\n",
            "Non-trainable params: 480\n",
            "_________________________________________________________________\n",
            "Training on fold 1/5...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 89600 samples, validate on 22400 samples\n",
            "Epoch 1/60\n",
            "89600/89600 [==============================] - 7s 79us/step - loss: 0.5602 - get_f1: 0.8666 - get_recall: 0.8666 - val_loss: 0.0750 - val_get_f1: 0.9704 - val_get_recall: 0.9704\n",
            "Epoch 2/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.3396 - get_f1: 0.9388 - get_recall: 0.9388 - val_loss: 0.1192 - val_get_f1: 0.9549 - val_get_recall: 0.9549\n",
            "Epoch 3/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.2954 - get_f1: 0.9499 - get_recall: 0.9499 - val_loss: 0.2630 - val_get_f1: 0.8977 - val_get_recall: 0.8977\n",
            "Epoch 4/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.2777 - get_f1: 0.9512 - get_recall: 0.9512 - val_loss: 0.0791 - val_get_f1: 0.9757 - val_get_recall: 0.9757\n",
            "Epoch 5/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.2684 - get_f1: 0.9523 - get_recall: 0.9523 - val_loss: 0.0580 - val_get_f1: 0.9785 - val_get_recall: 0.9785\n",
            "Epoch 6/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2624 - get_f1: 0.9514 - get_recall: 0.9514 - val_loss: 0.2668 - val_get_f1: 0.9625 - val_get_recall: 0.9625\n",
            "Epoch 7/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2553 - get_f1: 0.9536 - get_recall: 0.9536 - val_loss: 0.0528 - val_get_f1: 0.9825 - val_get_recall: 0.9825\n",
            "Epoch 8/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2557 - get_f1: 0.9555 - get_recall: 0.9555 - val_loss: 0.1190 - val_get_f1: 0.9737 - val_get_recall: 0.9737\n",
            "Epoch 9/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2476 - get_f1: 0.9557 - get_recall: 0.9557 - val_loss: 0.1246 - val_get_f1: 0.9508 - val_get_recall: 0.9508\n",
            "Epoch 10/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2390 - get_f1: 0.9583 - get_recall: 0.9583 - val_loss: 0.1998 - val_get_f1: 0.9658 - val_get_recall: 0.9658\n",
            "Epoch 11/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2410 - get_f1: 0.9554 - get_recall: 0.9554 - val_loss: 0.1931 - val_get_f1: 0.9217 - val_get_recall: 0.9217\n",
            "Epoch 12/60\n",
            "89600/89600 [==============================] - 6s 67us/step - loss: 0.2479 - get_f1: 0.9566 - get_recall: 0.9566 - val_loss: 0.0843 - val_get_f1: 0.9791 - val_get_recall: 0.9791\n",
            "Epoch 13/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2441 - get_f1: 0.9540 - get_recall: 0.9540 - val_loss: 0.0984 - val_get_f1: 0.9660 - val_get_recall: 0.9660\n",
            "Epoch 14/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2316 - get_f1: 0.9593 - get_recall: 0.9593 - val_loss: 0.0534 - val_get_f1: 0.9784 - val_get_recall: 0.9784\n",
            "Epoch 15/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2314 - get_f1: 0.9619 - get_recall: 0.9619 - val_loss: 0.0567 - val_get_f1: 0.9807 - val_get_recall: 0.9807\n",
            "Epoch 16/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.2206 - get_f1: 0.9616 - get_recall: 0.9616 - val_loss: 0.0609 - val_get_f1: 0.9787 - val_get_recall: 0.9787\n",
            "Epoch 17/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2246 - get_f1: 0.9635 - get_recall: 0.9635 - val_loss: 0.1116 - val_get_f1: 0.9752 - val_get_recall: 0.9752\n",
            "Epoch 18/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2203 - get_f1: 0.9610 - get_recall: 0.9610 - val_loss: 0.0493 - val_get_f1: 0.9847 - val_get_recall: 0.9847\n",
            "Epoch 19/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2238 - get_f1: 0.9607 - get_recall: 0.9607 - val_loss: 0.0942 - val_get_f1: 0.9636 - val_get_recall: 0.9636\n",
            "Epoch 20/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2180 - get_f1: 0.9630 - get_recall: 0.9630 - val_loss: 0.0976 - val_get_f1: 0.9799 - val_get_recall: 0.9799\n",
            "Epoch 21/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.2066 - get_f1: 0.9643 - get_recall: 0.9643 - val_loss: 2.7844 - val_get_f1: 0.0707 - val_get_recall: 0.0707\n",
            "Epoch 22/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2087 - get_f1: 0.9627 - get_recall: 0.9627 - val_loss: 0.0524 - val_get_f1: 0.9835 - val_get_recall: 0.9835\n",
            "Epoch 23/60\n",
            "89600/89600 [==============================] - 6s 68us/step - loss: 0.2048 - get_f1: 0.9621 - get_recall: 0.9621 - val_loss: 0.0515 - val_get_f1: 0.9849 - val_get_recall: 0.9849\n",
            "Epoch 24/60\n",
            "89600/89600 [==============================] - 7s 78us/step - loss: 0.2062 - get_f1: 0.9639 - get_recall: 0.9639 - val_loss: 0.4890 - val_get_f1: 0.8115 - val_get_recall: 0.8115\n",
            "Epoch 25/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2008 - get_f1: 0.9648 - get_recall: 0.9648 - val_loss: 0.0632 - val_get_f1: 0.9765 - val_get_recall: 0.9765\n",
            "Epoch 26/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.1991 - get_f1: 0.9651 - get_recall: 0.9651 - val_loss: 0.0919 - val_get_f1: 0.9675 - val_get_recall: 0.9675\n",
            "Epoch 27/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1972 - get_f1: 0.9648 - get_recall: 0.9648 - val_loss: 0.2275 - val_get_f1: 0.9208 - val_get_recall: 0.9208\n",
            "Epoch 28/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.2008 - get_f1: 0.9654 - get_recall: 0.9654 - val_loss: 0.0553 - val_get_f1: 0.9847 - val_get_recall: 0.9847\n",
            "Epoch 29/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2068 - get_f1: 0.9645 - get_recall: 0.9645 - val_loss: 0.2956 - val_get_f1: 0.8808 - val_get_recall: 0.8808\n",
            "Epoch 30/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2007 - get_f1: 0.9655 - get_recall: 0.9655 - val_loss: 0.0894 - val_get_f1: 0.9747 - val_get_recall: 0.9747\n",
            "Epoch 31/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2003 - get_f1: 0.9646 - get_recall: 0.9646 - val_loss: 0.0463 - val_get_f1: 0.9830 - val_get_recall: 0.9830\n",
            "Epoch 32/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2003 - get_f1: 0.9647 - get_recall: 0.9647 - val_loss: 0.0558 - val_get_f1: 0.9836 - val_get_recall: 0.9836\n",
            "Epoch 33/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1950 - get_f1: 0.9655 - get_recall: 0.9655 - val_loss: 0.0480 - val_get_f1: 0.9838 - val_get_recall: 0.9838\n",
            "Epoch 34/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1982 - get_f1: 0.9646 - get_recall: 0.9646 - val_loss: 0.1476 - val_get_f1: 0.9326 - val_get_recall: 0.9326\n",
            "Epoch 35/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2011 - get_f1: 0.9638 - get_recall: 0.9638 - val_loss: 0.0542 - val_get_f1: 0.9821 - val_get_recall: 0.9821\n",
            "Epoch 36/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2004 - get_f1: 0.9660 - get_recall: 0.9660 - val_loss: 0.0674 - val_get_f1: 0.9731 - val_get_recall: 0.9731\n",
            "Epoch 37/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2019 - get_f1: 0.9656 - get_recall: 0.9656 - val_loss: 0.0499 - val_get_f1: 0.9829 - val_get_recall: 0.9829\n",
            "Epoch 38/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1932 - get_f1: 0.9667 - get_recall: 0.9667 - val_loss: 0.0456 - val_get_f1: 0.9831 - val_get_recall: 0.9831\n",
            "Epoch 39/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1981 - get_f1: 0.9655 - get_recall: 0.9655 - val_loss: 0.0747 - val_get_f1: 0.9802 - val_get_recall: 0.9802\n",
            "Epoch 40/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2009 - get_f1: 0.9647 - get_recall: 0.9647 - val_loss: 0.0808 - val_get_f1: 0.9746 - val_get_recall: 0.9746\n",
            "Epoch 41/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1980 - get_f1: 0.9651 - get_recall: 0.9651 - val_loss: 0.6975 - val_get_f1: 0.6767 - val_get_recall: 0.6767\n",
            "Epoch 42/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1992 - get_f1: 0.9646 - get_recall: 0.9646 - val_loss: 0.0463 - val_get_f1: 0.9824 - val_get_recall: 0.9824\n",
            "Epoch 43/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2030 - get_f1: 0.9651 - get_recall: 0.9651 - val_loss: 0.1492 - val_get_f1: 0.9429 - val_get_recall: 0.9429\n",
            "Epoch 44/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1926 - get_f1: 0.9660 - get_recall: 0.9660 - val_loss: 0.2325 - val_get_f1: 0.9097 - val_get_recall: 0.9097\n",
            "Epoch 45/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1864 - get_f1: 0.9656 - get_recall: 0.9656 - val_loss: 0.0499 - val_get_f1: 0.9829 - val_get_recall: 0.9829\n",
            "Epoch 46/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1934 - get_f1: 0.9676 - get_recall: 0.9676 - val_loss: 0.2596 - val_get_f1: 0.9737 - val_get_recall: 0.9737\n",
            "Epoch 47/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1995 - get_f1: 0.9642 - get_recall: 0.9642 - val_loss: 0.1775 - val_get_f1: 0.9254 - val_get_recall: 0.9254\n",
            "Epoch 48/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1920 - get_f1: 0.9669 - get_recall: 0.9669 - val_loss: 0.1061 - val_get_f1: 0.9587 - val_get_recall: 0.9588\n",
            "Epoch 49/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1903 - get_f1: 0.9675 - get_recall: 0.9675 - val_loss: 0.0537 - val_get_f1: 0.9810 - val_get_recall: 0.9810\n",
            "Epoch 50/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1922 - get_f1: 0.9652 - get_recall: 0.9652 - val_loss: 0.0536 - val_get_f1: 0.9804 - val_get_recall: 0.9804\n",
            "Epoch 51/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1955 - get_f1: 0.9673 - get_recall: 0.9673 - val_loss: 0.0505 - val_get_f1: 0.9818 - val_get_recall: 0.9818\n",
            "Epoch 52/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1826 - get_f1: 0.9665 - get_recall: 0.9665 - val_loss: 0.0938 - val_get_f1: 0.9819 - val_get_recall: 0.9819\n",
            "Epoch 53/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1913 - get_f1: 0.9655 - get_recall: 0.9655 - val_loss: 0.0534 - val_get_f1: 0.9770 - val_get_recall: 0.9770\n",
            "Epoch 54/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1914 - get_f1: 0.9666 - get_recall: 0.9666 - val_loss: 0.0462 - val_get_f1: 0.9845 - val_get_recall: 0.9845\n",
            "Epoch 55/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1882 - get_f1: 0.9675 - get_recall: 0.9675 - val_loss: 0.1285 - val_get_f1: 0.9390 - val_get_recall: 0.9390\n",
            "Epoch 56/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1946 - get_f1: 0.9662 - get_recall: 0.9662 - val_loss: 0.1103 - val_get_f1: 0.9757 - val_get_recall: 0.9757\n",
            "Epoch 57/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.1860 - get_f1: 0.9672 - get_recall: 0.9672 - val_loss: 0.0612 - val_get_f1: 0.9833 - val_get_recall: 0.9833\n",
            "Epoch 58/60\n",
            "89600/89600 [==============================] - 6s 69us/step - loss: 0.1864 - get_f1: 0.9677 - get_recall: 0.9677 - val_loss: 0.0593 - val_get_f1: 0.9804 - val_get_recall: 0.9804\n",
            "Epoch 59/60\n",
            "89600/89600 [==============================] - 6s 72us/step - loss: 0.1926 - get_f1: 0.9655 - get_recall: 0.9655 - val_loss: 0.0494 - val_get_f1: 0.9819 - val_get_recall: 0.9819\n",
            "Epoch 60/60\n",
            "89600/89600 [==============================] - 7s 74us/step - loss: 0.2010 - get_f1: 0.9656 - get_recall: 0.9656 - val_loss: 0.1413 - val_get_f1: 0.9711 - val_get_recall: 0.9711\n",
            "22400/22400 [==============================] - 1s 24us/step\n",
            "F1 score for this fold is :  0.38285714285714284\n",
            "Training on fold 2/5...\n",
            "Train on 89600 samples, validate on 22400 samples\n",
            "Epoch 1/60\n",
            "89600/89600 [==============================] - 7s 79us/step - loss: 0.5607 - get_f1: 0.8617 - get_recall: 0.8617 - val_loss: 0.0857 - val_get_f1: 0.9608 - val_get_recall: 0.9608\n",
            "Epoch 2/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.3275 - get_f1: 0.9367 - get_recall: 0.9367 - val_loss: 0.1278 - val_get_f1: 0.9525 - val_get_recall: 0.9525\n",
            "Epoch 3/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2845 - get_f1: 0.9494 - get_recall: 0.9494 - val_loss: 0.1617 - val_get_f1: 0.9460 - val_get_recall: 0.9460\n",
            "Epoch 4/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2680 - get_f1: 0.9530 - get_recall: 0.9530 - val_loss: 0.0859 - val_get_f1: 0.9689 - val_get_recall: 0.9689\n",
            "Epoch 5/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2604 - get_f1: 0.9540 - get_recall: 0.9540 - val_loss: 0.0776 - val_get_f1: 0.9701 - val_get_recall: 0.9701\n",
            "Epoch 6/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2533 - get_f1: 0.9549 - get_recall: 0.9549 - val_loss: 0.1993 - val_get_f1: 0.9500 - val_get_recall: 0.9500\n",
            "Epoch 7/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2806 - get_f1: 0.9487 - get_recall: 0.9487 - val_loss: 0.1412 - val_get_f1: 0.9654 - val_get_recall: 0.9654\n",
            "Epoch 8/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2581 - get_f1: 0.9503 - get_recall: 0.9503 - val_loss: 0.1648 - val_get_f1: 0.9649 - val_get_recall: 0.9649\n",
            "Epoch 9/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2477 - get_f1: 0.9525 - get_recall: 0.9525 - val_loss: 0.0667 - val_get_f1: 0.9770 - val_get_recall: 0.9770\n",
            "Epoch 10/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2462 - get_f1: 0.9530 - get_recall: 0.9530 - val_loss: 0.0737 - val_get_f1: 0.9738 - val_get_recall: 0.9738\n",
            "Epoch 11/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2446 - get_f1: 0.9540 - get_recall: 0.9540 - val_loss: 0.0615 - val_get_f1: 0.9802 - val_get_recall: 0.9802\n",
            "Epoch 12/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2289 - get_f1: 0.9591 - get_recall: 0.9591 - val_loss: 0.1646 - val_get_f1: 0.9403 - val_get_recall: 0.9403\n",
            "Epoch 13/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2243 - get_f1: 0.9599 - get_recall: 0.9599 - val_loss: 0.2584 - val_get_f1: 0.8887 - val_get_recall: 0.8887\n",
            "Epoch 14/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2244 - get_f1: 0.9583 - get_recall: 0.9583 - val_loss: 0.1659 - val_get_f1: 0.9733 - val_get_recall: 0.9733\n",
            "Epoch 15/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2283 - get_f1: 0.9590 - get_recall: 0.9590 - val_loss: 0.2677 - val_get_f1: 0.9725 - val_get_recall: 0.9725\n",
            "Epoch 16/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2305 - get_f1: 0.9590 - get_recall: 0.9590 - val_loss: 0.1372 - val_get_f1: 0.9774 - val_get_recall: 0.9774\n",
            "Epoch 17/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2228 - get_f1: 0.9617 - get_recall: 0.9617 - val_loss: 0.0712 - val_get_f1: 0.9689 - val_get_recall: 0.9689\n",
            "Epoch 18/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2308 - get_f1: 0.9570 - get_recall: 0.9570 - val_loss: 0.5624 - val_get_f1: 0.7262 - val_get_recall: 0.7262\n",
            "Epoch 19/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2169 - get_f1: 0.9606 - get_recall: 0.9606 - val_loss: 0.2498 - val_get_f1: 0.9039 - val_get_recall: 0.9039\n",
            "Epoch 20/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2163 - get_f1: 0.9609 - get_recall: 0.9609 - val_loss: 0.0724 - val_get_f1: 0.9697 - val_get_recall: 0.9697\n",
            "Epoch 21/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2226 - get_f1: 0.9610 - get_recall: 0.9610 - val_loss: 2.1918 - val_get_f1: 0.2229 - val_get_recall: 0.2229\n",
            "Epoch 22/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2264 - get_f1: 0.9597 - get_recall: 0.9597 - val_loss: 0.0690 - val_get_f1: 0.9814 - val_get_recall: 0.9814\n",
            "Epoch 23/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2329 - get_f1: 0.9586 - get_recall: 0.9586 - val_loss: 0.0706 - val_get_f1: 0.9816 - val_get_recall: 0.9816\n",
            "Epoch 24/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2439 - get_f1: 0.9568 - get_recall: 0.9568 - val_loss: 0.3074 - val_get_f1: 0.8960 - val_get_recall: 0.8960\n",
            "Epoch 25/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2390 - get_f1: 0.9570 - get_recall: 0.9570 - val_loss: 0.1026 - val_get_f1: 0.9599 - val_get_recall: 0.9599\n",
            "Epoch 26/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2487 - get_f1: 0.9548 - get_recall: 0.9548 - val_loss: 0.0581 - val_get_f1: 0.9791 - val_get_recall: 0.9791\n",
            "Epoch 27/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2461 - get_f1: 0.9613 - get_recall: 0.9613 - val_loss: 0.1979 - val_get_f1: 0.9281 - val_get_recall: 0.9281\n",
            "Epoch 28/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2400 - get_f1: 0.9602 - get_recall: 0.9602 - val_loss: 0.0488 - val_get_f1: 0.9829 - val_get_recall: 0.9829\n",
            "Epoch 29/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2267 - get_f1: 0.9607 - get_recall: 0.9607 - val_loss: 0.0546 - val_get_f1: 0.9818 - val_get_recall: 0.9818\n",
            "Epoch 30/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2284 - get_f1: 0.9609 - get_recall: 0.9609 - val_loss: 0.0662 - val_get_f1: 0.9766 - val_get_recall: 0.9766\n",
            "Epoch 31/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2172 - get_f1: 0.9619 - get_recall: 0.9619 - val_loss: 0.1446 - val_get_f1: 0.9373 - val_get_recall: 0.9373\n",
            "Epoch 32/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2093 - get_f1: 0.9627 - get_recall: 0.9627 - val_loss: 1.4723 - val_get_f1: 0.2926 - val_get_recall: 0.2926\n",
            "Epoch 33/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2144 - get_f1: 0.9614 - get_recall: 0.9614 - val_loss: 0.0573 - val_get_f1: 0.9781 - val_get_recall: 0.9781\n",
            "Epoch 34/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2143 - get_f1: 0.9630 - get_recall: 0.9630 - val_loss: 0.0563 - val_get_f1: 0.9800 - val_get_recall: 0.9800\n",
            "Epoch 35/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2170 - get_f1: 0.9606 - get_recall: 0.9606 - val_loss: 0.0916 - val_get_f1: 0.9592 - val_get_recall: 0.9592\n",
            "Epoch 36/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2221 - get_f1: 0.9631 - get_recall: 0.9631 - val_loss: 0.1051 - val_get_f1: 0.9779 - val_get_recall: 0.9779\n",
            "Epoch 37/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2202 - get_f1: 0.9611 - get_recall: 0.9611 - val_loss: 0.0592 - val_get_f1: 0.9813 - val_get_recall: 0.9813\n",
            "Epoch 38/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2276 - get_f1: 0.9600 - get_recall: 0.9600 - val_loss: 0.0763 - val_get_f1: 0.9738 - val_get_recall: 0.9738\n",
            "Epoch 39/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2242 - get_f1: 0.9612 - get_recall: 0.9612 - val_loss: 0.0626 - val_get_f1: 0.9799 - val_get_recall: 0.9799\n",
            "Epoch 40/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2189 - get_f1: 0.9611 - get_recall: 0.9611 - val_loss: 0.0889 - val_get_f1: 0.9750 - val_get_recall: 0.9750\n",
            "Epoch 41/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2139 - get_f1: 0.9596 - get_recall: 0.9596 - val_loss: 2.2266 - val_get_f1: 0.2034 - val_get_recall: 0.2034\n",
            "Epoch 42/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2050 - get_f1: 0.9625 - get_recall: 0.9625 - val_loss: 0.0598 - val_get_f1: 0.9817 - val_get_recall: 0.9817\n",
            "Epoch 43/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2181 - get_f1: 0.9600 - get_recall: 0.9600 - val_loss: 2.0457 - val_get_f1: 0.2382 - val_get_recall: 0.2382\n",
            "Epoch 44/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2165 - get_f1: 0.9613 - get_recall: 0.9613 - val_loss: 0.1807 - val_get_f1: 0.9694 - val_get_recall: 0.9694\n",
            "Epoch 45/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2083 - get_f1: 0.9620 - get_recall: 0.9620 - val_loss: 0.0493 - val_get_f1: 0.9821 - val_get_recall: 0.9821\n",
            "Epoch 46/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2181 - get_f1: 0.9604 - get_recall: 0.9604 - val_loss: 0.2243 - val_get_f1: 0.8962 - val_get_recall: 0.8963\n",
            "Epoch 47/60\n",
            "89600/89600 [==============================] - 6s 72us/step - loss: 0.2143 - get_f1: 0.9621 - get_recall: 0.9621 - val_loss: 0.1136 - val_get_f1: 0.9442 - val_get_recall: 0.9442\n",
            "Epoch 48/60\n",
            "89600/89600 [==============================] - 7s 73us/step - loss: 0.1991 - get_f1: 0.9641 - get_recall: 0.9641 - val_loss: 0.0670 - val_get_f1: 0.9804 - val_get_recall: 0.9804\n",
            "Epoch 49/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2193 - get_f1: 0.9592 - get_recall: 0.9592 - val_loss: 0.0459 - val_get_f1: 0.9814 - val_get_recall: 0.9814\n",
            "Epoch 50/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2255 - get_f1: 0.9590 - get_recall: 0.9590 - val_loss: 0.0602 - val_get_f1: 0.9772 - val_get_recall: 0.9772\n",
            "Epoch 51/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.2050 - get_f1: 0.9628 - get_recall: 0.9628 - val_loss: 0.5136 - val_get_f1: 0.6874 - val_get_recall: 0.6874\n",
            "Epoch 52/60\n",
            "89600/89600 [==============================] - 6s 71us/step - loss: 0.1985 - get_f1: 0.9641 - get_recall: 0.9641 - val_loss: 0.1309 - val_get_f1: 0.9751 - val_get_recall: 0.9751\n",
            "Epoch 53/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.2024 - get_f1: 0.9619 - get_recall: 0.9619 - val_loss: 0.1071 - val_get_f1: 0.9526 - val_get_recall: 0.9526\n",
            "Epoch 54/60\n",
            "89600/89600 [==============================] - 6s 70us/step - loss: 0.1992 - get_f1: 0.9636 - get_recall: 0.9636 - val_loss: 0.0586 - val_get_f1: 0.9817 - val_get_recall: 0.9817\n",
            "Epoch 55/60\n",
            "38144/89600 [===========>..................] - ETA: 3s - loss: 0.1982 - get_f1: 0.9630 - get_recall: 0.9630"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qR1ILk9sWm3",
        "colab_type": "code",
        "outputId": "4e15bc8a-c102-4aae-c285-16b9f103d4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Training Error\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = best_model.predict(train_seqs_onehot, batch_size=BATCHSIZE, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(train_labels, y_pred_bool))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "112000/112000 [==============================] - 6s 53us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.81      0.90    107787\n",
            "           1       0.17      0.97      0.29      4213\n",
            "\n",
            "    accuracy                           0.82    112000\n",
            "   macro avg       0.58      0.89      0.59    112000\n",
            "weighted avg       0.97      0.82      0.87    112000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUlOIEMzxP6p",
        "colab_type": "code",
        "outputId": "7ffdd24a-6d7c-4643-f388-85c6594dbf2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred = best_model.predict(test_seqs_onehot, batch_size=BATCHSIZE,verbose = 1)\n",
        "res = np.argmax(y_pred, axis=1)\n",
        "print(np.sum(res))\n",
        "\n",
        "res = pd.DataFrame(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 2s 47us/step\n",
            "2187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux7REfQX0Uhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res.to_csv(\"./prediction.csv\", index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}